---
title: ""
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    
  html_document:
    css: custom.css
    toc: true
    toc_float: true
    code_folding: hide
    fig_caption: yes
    self_contained: yes
    # template: html_template.html 
    
  word_document: 
    toc: true
    fig_caption: yes
    
  pdf_document:
    fig_caption: yes
    always_allow_html: yes
    editor_options: 
  
  chunk_output_type: console

params:
  dhis_instance: Malawi
  data_directory: datasets
  output_directory: ./ # bug: only uses current directory
  output_format: html_document
  cache: TRUE
  echo: FALSE
---

<!-- NB:  If cache = TRUE, MUST clear cache when changing to country for review.  If not, markdown throws error: 'Error: path for html_dependency not found:' -->

# **`r toupper( params$dhis_instance )` 

# DHIS2 Metadata** {.tabset .tabset-fade}


```{r packages, echo = TRUE, cache=FALSE, warning=FALSE, include = FALSE }


# list of required packages
    package.list = c( 'zoo' , "tidyverse" ,"rlist", "listviewer", "DT", "knitr", "kableExtra", "xts", "leaflet", "geojsonR", "wellknown" , "geojsonio" , "sp" , "rmapshaper" , "rgeos" , "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "anytime" , "scales", "RcppRoll", "zoo", "tsibble", "seasonal", "forecast", "stlplus",  "gridExtra", "futile.logger", "Hmisc", "pander" , "stringi", "rlang" , "htmltools" , "tidyselect" , "broom" , "ggthemes" , "readxl", "knitrProgressBar" , 'osmdata', 'sf' ,  "geojsonsf" , 'tmap', 'formattable'  )

# Function to test if package is installed 
    pkgTest <- function( package.list = package.list ){
        
        missing.packages = setdiff( package.list , rownames(installed.packages())) 
        if ( length( missing.packages ) > 0 ) install.packages( missing.packages ) 
    }


# Test if packages loaded
    pkgTest( package.list )

# load the packages
    suppressMessages( 
      lapply( package.list,  require , character.only = TRUE)
    )


knitr::opts_chunk$set( echo = params$echo ,
                       fig.width =  3.5, 
                       fig.height = 4,
                       dpi = 300 ,
                       # knitr.table.format = "html" ,
                       cache = params$cache # TRUE for testing; FALSE for production
                       )

```


```{r sources, cache = FALSE}

  # functions for fetching metadata

  source( 'dhis2_functions.R'  )

```


```{r knitr_setup, include = FALSE }

  knitr::opts_chunk$set( echo = params$echo ,
                       comment = "" ,
                       warning = FALSE, 
                       cache = params$cache , 
                       fig.width =  8 ,
                       fig.height = 8
                       )


    # Country/Instance folder
    dhis_instance = params$dhis_instance
    
    origin.folder = paste0( dhis_instance , "/")
     
    if (!dir.exists( origin.folder ) ) dir.create( origin.folder )
    
    
    # sub-folder for data
    dataset.directory = paste0( origin.folder , params$data_directory , "/" )
    
    if (!dir.exists( dataset.directory ) ) dir.create(  dataset.directory )
  
    
    # Type of output:  html, pdf, doc..
    output_format = params$output_format
    
    
    # this folder will hold output of the metadata and data reviews
    output.directory =  ifelse( is.null( params$output_directory ) , 
                                origin.folder , # the directory where this file sits. 
                                paste0(  params$output_directory , "/" , origin.folder )
    )
    
   
    
    
    outputs = tibble( 
        output_format = c(  "html_document", 'word_document'),
        output_suffix = c(  "html", 'docx' )
    )
    
    output.suffix = outputs %>% 
        filter( output_format == params$output_format ) %>% 
        .$output_suffix
    
    
 

   
    # list for passing to parameters to sub-documents
    params.list = list(
        dhis_instance = params$dhis_instance , # selects dhis2 instance
        data_directory = params$data_directory ,  # root data directory
        output_directory = params$output_directory ,
        output_format = params$output_format ,
        cache = FALSE ,
        echo = FALSE 
    )

    
  

    
```

<!-- Define the year-month time periods for the review -->

<!-- NB:  What about IDSR with weeks?  -->

```{r date_strings }

  periods = date_code() # default: 2013-2017
  # periods = date_code( 2017, 1 ) # January 2017 only
  
  # as character vector
  periods.vector = strsplit( periods, ";" , fixed = TRUE )[[1]]

  
```

## About DHIS2

```{r}
system_data_file = paste0( dataset.directory , dhis_instance, "_system_data.rds" ) 

system_data = readRDS( system_data_file )

kable( t( system_data ) )
```

## Structure

```{r}

  meta_data_file = paste0( dataset.directory ,
                           dhis_instance, 
                           "_metadata.rds" ) 

    md = read_rds( meta_data_file ) 
    
    # re-order
    md = md[ order( names(md) ) ]

# Retrieve access data 
  date_metadata = file.info( meta_data_file )$ctime 

```


Results shown are for data accessed on **`r format(date_metadata, "%d %B %Y") `**.   
```{r list_viewer, eval= FALSE }
 jsonedit( md )
```

## List

```{r attribute_numbers }

 metadata_attributes = map_df( md[names(md)], length ) %>% 
    gather( attribute, value ) %>% # columns to rows
    mutate( value = comma( value ) )   # format numbers
    

  metadata_attributes %>%
      pander( align = c( 'l', 'r' )  ) 
  # %>% 
  #     pander_styling(  bootstrap_options = c("striped", "hover") ) %>%
  #       column_spec(1, bold = T) %>%
  #     scroll_box(height = "500px")

```

# Organisational Units {.tabset .tabset-fade}

There are `r  md$organisationUnits %>% nrow %>% comma()` organisation units in `r  md$organisationUnitLevels %>% nrow` levels. Of these, `r sum( map_lgl( md$organisationUnits$attributeValues , ~length(.x) > 0 ) )` are assigned an attribute.  


## Organizational Units and levels

```{r ou_and_levels }
  
  ous =  ous_from_metatdata( md )

  # glimpse( ous )
   
  ousFeatures = count( ous %>% as_tibble() ,
                       level, level.name , feature ) %>% 
      spread(  feature, n ) %>%
      rename( No_Coordinates = `<NA>` ,
              Level = level , 
              Name = level.name)
  
  pander( ousFeatures, align = c( 'l', 'l', 'r' ) ,
                caption = paste( "Numbers of Organisational Unit Levels and GIS coordinates" ) 
          # ,  bootstrap_options = c("striped", "hover")
          )

```

Listing of Org Units without coordinates (limit 25)

```{r limit_display_missing_coordinates }

limit_to_levels = ousFeatures %>% 
  mutate( c = cumsum(replace_na( No_Coordinates, 0)) ) %>%
  filter( c<25 ) %>%
  pull( Level )

listing_no_coordinates = ous %>% as_tibble() %>%
  filter( 
    level %in% limit_to_levels ,
    is.na( coordinates ) ) %>%
  select( orgUnit.name , openingDate , closedDate , parent_ou.name )

pander( listing_no_coordinates )

```

## Numbers of orgUnits by level, by year


```{r ous_charts_by_level}

 # vector of periods as dates
  p = strsplit( periods , ";" , fixed = TRUE )[[1]]
  p = paste0( p , "01")
  p = ymd( p )
  
  levels = ou_levels( md , name = FALSE ) 
  level.names = ou_levels( md , name = TRUE ) 
  
  
  # number of units per level
  ou_numbers_file = paste0( dataset.directory ,
                           dhis_instance, 
                           "_ou_numbers.rds" ) 
  
  if ( !file.exists( ou_numbers_file ) ){
     n.level = list()
     for ( i in seq_along( levels ) ){
        
        n = map_df(  p , ~ous %>% as_tibble %>%
                        filter( level , level.name %in% level.names[i] ,
                                openingDate < .x   , 
                                ( closedDate > .x | is.na( closedDate ) )
                              ) %>%
                        mutate( period = .x ) %>%
                        count( level , level.name , period, feature ) 
        ) 
        
        n.level[[i]] = n 
     }
     
     n.level.df = bind_rows( n.level ) %>% 
       # remove layer where count is always one (national layer)
       group_by( level ) %>%
       mutate( max = max( n , na.rm =  TRUE ) ) %>%
       filter( max > 1 )
     
     # replace missing feature with 'No_Coordinates'
     n.level.df$feature[ is.na( n.level.df$feature )] = 'None'
    
    # convert month-Yr to dat
    n.level.df$month = fast_strptime( as.character(  n.level.df$period ) , "%Y-%m-%d") %>% as.yearmon()
    
    saveRDS(  n.level.df , file = ou_numbers_file )
    
  } else {
    
    n.level.df = readRDS( ou_numbers_file )
  }
  
  ggplot( n.level.df,  aes(x = month, y = as.integer(n), group = feature , color = feature )) + 
      geom_line( size = 1 ) +
      expand_limits( y = 0 ) +
      scale_x_yearmon( format = "%Y" ) +
      scale_color_discrete("Coordinates") +
      theme_minimal() + 
      labs( title = "Monthly Number of orgUnits" , y = " " , x ="") +
      facet_wrap( level ~ level.name , scales = 'free' )


```

```{r orgUnits_over_time_table }

n.level.table = n.level.df %>%
  mutate( year = year( period ) ) %>%
  group_by( level, level.name , feature, year ) %>%
  summarise( n = max(n) ) %>%
  arrange( level, level.name , feature, year ) %>%
  summarise( 
    Start = first( n ) ,
    End = last( n ) ,
    change = last(n) - first(n) ,
    percent = scales::percent( ( last(n) - first(n) ) / first(n) )
    
    ) %>%
  # spread( feature , change ) %>%
  arrange( level ) %>% ungroup() %>% select( -level ) %>%
  rename( Geometry = feature )

pander( n.level.table )
```

<!-- NB: not all ou will be assigned to a dataset, and some may be duplicates... -->

<!-- NB : stratify by attributes such as private, public--if available -->


## Administrative boundaries and facilities 

```{r ou_admins_and_hf }
admins = ous %>% filter( feature %in% 'Polygon'  )

hf = ous %>% filter( feature %in% 'Point'  )

```

<!-- TODO update imputed section -->

```{r table_imputed_ou , eval=FALSE}

# imputed 
count( facilities , has.coordinates, impute )

```


- Number of orgunits per administrative area 

```{r orgunit.per.area  }

#  count units per parentid and join with admins
facilitiescount = hf %>% st_set_geometry(NULL) %>% count( parent_ou ) 

# admins.count = admins %>% 
#   filter( level %in% 3 ) %>%
#   # as_tibble() %>%
#   # select( -geometry) %>%
#     st_join( facilitiescount , join = st_within )  

admins_hf_count = merge( admins %>% filter( level == 3 ) ,
                         facilitiescount , by.x = "orgUnit" , by.y = "parent_ou" ,
                         all.x = TRUE )

# pander( admins.count %>% ungroup %>% as_tibble() %>% select( orgUnit.name , n, -geometry ) ) 

tm_shape( admins_hf_count ) + 
  tm_polygons("n") +
  tm_layout( frame = FALSE  , legend.outside = TRUE )

# admins.count$polygons = admins$polygons
# admins.count$lat = geosphere::centroid( admins$polygons )[, 2 ]
# admins.count$long = geosphere::centroid( admins$polygons )[, 1 ]


# Map of regions with HFC
admins %>%
    filter( level %in% 2 ) %>%
    rename( Region = orgUnit.name ) %>%
  
    tm_shape( . ) + 
    tm_polygons( "Region" ) + 
    # tm_dots( "HF" ) +
    tm_layout( frame = FALSE  , legend.outside = TRUE ) +
  
    tm_shape( hf %>% mutate( level = factor( level ) )  ) +  
    tm_dots( "level" , alpha = .2, col = 'black' , size = .01, 
             border.alpha = .2, border.col = 'black' )
```

```{r ou_maps_additional , eval=FALSE}
# Map of regions 
admins %>%
    filter( level %in% 2 ) %>%
    rename( Region = orgUnit.name ) %>%
    tm_shape( .   ) + 
    tm_polygons( "Region") + 
    # tm_dots( "HF" ) +
    tm_layout( frame = FALSE , legend.outside = TRUE )

# Map of districts 
admins %>%
    filter( level %in% 3 ) %>%
    rename( District = orgUnit.name ) %>%
    tm_shape( . ) + 
    tm_polygons( "District" ) + 
    tm_layout( frame = FALSE , legend.outside = TRUE ) 
    

# map of HF -- note that this is all facilities, regardless of whether it supplies OPD data
hf %>%
    # filter( level %in% 3 ) %>%
    mutate( level = factor( level ) ) %>%
    rename( HF = orgUnit.name ) %>%
    tm_shape( . ) + 
    # tm_
    # tm_dots( "level" ) + 
    tm_dots( 'HF' ) + 
    tm_layout( frame = FALSE ) + 
    tm_legend(show=FALSE)
    
```

## Categories linked with orgUnits
  
NB  confirm whether all units assigned to category

# Data Elements {.tabset .tabset-fade}

There are `r  md$dataElements %>% nrow %>% comma()` data elements. To help identify relevant elements, we used several searches of the data element names.   

# Number of facilities reporting each data element

```{r d.reported_data }

    reported_data_file = paste0( origin.folder ,
                           dhis_instance, 
                           "_reported.rds" ) 
  
     d.reported =  readRDS( reported_data_file )
     
```


A list of variables was queried to see how many org units submitted data last year.  In total, there were `r  nrow( d.reported ) %>% scales::comma() ` variables queried. Of these, there were `r sum( !is.na(d.reported$value ) ) ` variables that were submitted by at least one org unit.  A listing of the variable can be found in the spreadsheet `r dhis_instance`_dataElements.xlsx.  


```{r dsde_data }
# data frame of datasets and data elements
  dsde = dataSet_dataElement_df( md )
```


```{r options_per_category }

# number of options in each catgory combo

options = md$categoryCombos %>% 
    select( id, categories) %>% 
    unnest( categories ) %>%
    rename( categoryCombo = id , category = id1 ) %>%
    inner_join( md$categories  %>% select( id, categoryOptions ), 
                by = c('category' = 'id' )
                ) %>%
    unnest( categoryOptions ) %>% 
    count( categoryCombo ) %>%
    rename( n_options = n )


open_ou =     md$organisationUnits %>% 
    select( id, closedDate) %>%
    filter( is.na(closedDate) ) %>%
    select( id )

n_facilities_assigned_to_datasets = md$dataSets %>%
    select( id, organisationUnits) %>%
    rename( dataSet.id = id ) %>% 
    unnest( organisationUnits ) %>%
    inner_join( open_ou , by = 'id' ) %>%
    count( dataSet.id ) %>%
    rename( n_facilities = n )

display.vars = c('name', 'zeroIsSignificant', 'lastUpdated',
                                 'categoryCombo', 'id' )

de = md$dataElements[, display.vars ]
    
    # Convert category combo from df to list (ends up with id as character)
    de[, 'categoryCombo' ] = as.list( de[, 'categoryCombo' ] )

d.mal.reported = d.reported[ , c("dataElement", "value")] %>% 
    
    rename( dataElement.id = dataElement ) %>%
    
    right_join( 
        
        de %>% rename( dataElement = name ), 
        
        by = c("dataElement.id" = "id") 
        
        ) %>%
    
    left_join(
        
        options ,
        
        by = 'categoryCombo'
        
        ) %>%
    
   left_join( 
       
       dsde %>% select( dataElement.id , dataSet.id ) , 
       
       by = 'dataElement.id' 
       
       ) %>%
    
   left_join( 
       
       md$dataSets %>% select( id, name, periodType, timelyDays ) %>%
           rename( dataSet = name ),
       
       by = c( 'dataSet.id' = 'id' )
       
       ) %>%
    
    left_join( 
        
        n_facilities_assigned_to_datasets , by = 'dataSet.id'
        
        ) %>%

    mutate( 
        
        val = as.integer(value) 

        , frequency = case_when(
            periodType %in% "Weekly" ~ 52 ,
            periodType %in% "Monthly" ~ 12 ,
            periodType  %in% "Quarterly" ~ 4 ,
            periodType  %in% "Yearly" ~ 1 ,
            TRUE ~ 1
        )
            
        , pVal = val / (frequency * n_facilities * n_options ) 

            
        ) %>% 
    
    mutate( 
                Percent_Reported = sprintf("%1.2f%%", 100 * pVal ) 
                ) 

# If a data element linked to >1 dataSet, select the one with greatest number of facilities
    d.mal.reported = d.mal.reported %>%
        group_by( dataElement  ) %>%
        arrange( -n_facilities  ) %>%
        filter(  row_number() == 1 ) %>%
        arrange( desc(pVal) ) 

   # pander( d.mal.reported )
```

## suggested key data elements

```{r suggeest_key_elements }

 de.key = d.mal.reported %>%
    filter( pVal > .3 ) %>%
    arrange( dataSet , dataElement ) %>%
    select( dataSet , dataElement , periodType, 
            n_facilities, Percent_Reported , categoryCombo )
```

# Categories


How many **categories** are there? `r length( md$categories$id ) `

```{r list_categories }
    md$categories %>% select( id , name ) %>%
    # walk( print( paste( "There are" , length(md$categories$id ) , 
                 # "categories.") 
                 # )
          # ) %>% 
    datatable
```

How many **category combos** are there?
`r paste( "There are" , nrow( md$categoryCombos) %>% comma , 
                 "category combos, with", 
                 md$categoryCombos$categories %>% 
                     unlist %>% 
                     n_distinct( ),
                 "categories.") `

```{r list_category_combos }
    # md$categoryCombos %>% select( id , name ) 

    cc = tibble(
        categoryCombo.id = md$categoryCombos$id ,
        categoryCombo = md$categoryCombos$name ,
        category.id = md$categoryCombos$categories 
    ) %>%
        unnest() %>% 
        inner_join( md$categories %>% select( id, name) ,
                    by = 'id' ) %>%
        rename( Category = name ) %>%
        select( categoryCombo, Category ) 
    
    cc %>%
        filter( categoryCombo %in% 
                    ( count( cc, categoryCombo ) %>% 
                    filter( n > 1 ) %>% .$categoryCombo 
                    )
                ) %>% 
        datatable
```

How many **category options** are there? 
`r  paste( "There are" , nrow( md$categoryOptions) %>% comma, "category options."   )`

```{r}
    md$categoryOptions %>% select( id , name ) %>% 
    # walk( print( paste( "There are" , nrow(.) , 
    #              "category options."  
    #             ) 
    #              )
    #       ) %>% 
    datatable
```

Of these, how many category options are used in the category  option combos?
`r paste( "There are" , md$categoryOptionCombos$categoryOptions %>% 
    unlist %>% 
    n_distinct( ) %>% comma , 
                 "category options used in category option combos.") `

```{r}

    # md$categoryOptionCombos$categoryOptions %>% 
    # unlist %>% 
    # n_distinct( )

```

<!-- Are there more than one category associated with a category combo? -->

```{r}

 cco = 
  
  md$categoryOptionCombos %>% 
  select( id, name ) %>% 
  rename( categoryOptionCombo = name  ) %>%
  mutate( cc = md$categoryOptionCombos$categoryCombo$id ) %>%
  inner_join( md$categoryCombos %>% select( id, name ) %>% 
                rename( categoryCombo = name ),
              by = c( 'cc' = 'id' ) )%>% 
  group_by( cc, categoryCombo ) %>%
  summarise( 
    n_categories = n() , 
    categories = paste( categoryOptionCombo , collapse = ','  )
  )

```


```{r}
 md$dataSets %>% select( name) %>%
  mutate( cc = md$dataSets$categoryCombo$id ) %>% 
  # left_join( cco, by = 'cc' ) %>%
  datatable()
```

## Stockout categories

At least one country uses the category options to record stock outs.  This section searches for that possibility

```{r}

stock.categoryOptions = quo( grepl( 'stock|rupture' ,
                                    md$categoryOptions$name , 
                                    ignore.case = TRUE ) &
                                 grepl( 'out|rupture' ,
                                    md$categoryOptions$name , 
                                    ignore.case = TRUE ) 
                             )

search_text = f_rhs( stock.categoryOptions ) %>% deparse 

found_categories = eval_tidy( stock.categoryOptions )

Count = sum( found_categories  )

md$categoryOptions$name[ found_categories ]

```

There are `r Count` category options referencing stock out or stock rupture.


```{r}

stock.categoryOptionCombos = quo( grepl( 'stock' ,
                                    md$categoryOptionCombos$name , 
                                    ignore.case = TRUE ) 
                                  &
                                 grepl( 'out|rupture' ,
                                    md$categoryOptionCombos$name ,
                                    ignore.case = TRUE )
                             )

search_text = f_rhs( stock.categoryOptionCombos ) %>% deparse 

found_comboCategories = eval_tidy( stock.categoryOptionCombos )

Count = sum( found_comboCategories  )

md$categoryOptionCombos$name[ found_comboCategories ]

```

### Data Elements that use this stock out category option combo

TODO...


# Datasets {.tabset .tabset-fade} 

There are `r  md$dataSets %>% nrow %>% comma()` datasets. Of these, `r sum( map_lgl( md$dataSets$attributeValues , ~length(.x) > 0 ) )` are assigned an attribute.  



## All Datasets 

<!-- TODO: show dataset- group- and data elements together -->

```{r dataset_dataElement_categoryCombos}

dsde = dataSet_dataElement_df( md )

```

```{r datatable_dataElements}


d = dsde %>% 
    # join data elements 
    left_join( md$dataElements %>% 
                   select( name, id, domainType, aggregationType, valueType, zeroIsSignificant ) , 
                by = c('dataElement' = 'id' )
                ) %>%
    rename( dataElement.name = name ) %>%
    left_join( md$dataSets %>% 
                    select( name, id, periodType, timelyDays  ) , 
                by = c('dataSet' = 'id' )
                ) %>%
    rename( dataSet.name = name ) %>%
        left_join( md$categoryCombos %>%   
                        select( name, id , categories ) , 
                    by = c('categoryCombo' = 'id' )
                    ) %>% 
    rename( categoryCombos = name ) %>%
    mutate(
        # to keep all values, need to convert null to NA; 
        # otherwise unlist() drops the null values
        categories = map_chr( categories, 
                              ~ifelse( is.null(.x), NA, 
                                       paste( unlist(.x), collapse = ";" )
                              )
        )
    ) %>%
    left_join( md$categories %>% 
                    select( name, id ) , 
                by = c('categories' = 'id' )
                ) %>%
    select( -categories, -dataElement, -dataSet ) %>%
    rename( category = name , 
            dataElement = dataElement.name,
            dataSet = dataSet.name ) %>%
    mutate(
        Malaria =  grepl( 'malaria|palu' , dataElement , ignore.case = TRUE ) ,
        Malaria.conf = Malaria & grepl( 'conf' , dataElement, ignore.case = TRUE) ,
        Malaria.susp = Malaria & grepl( 'susp' , dataElement, ignore.case = TRUE) ,
        patients = grepl( 'patient' , dataElement , ignore.case = TRUE ) ,
        stock = grepl( 'stock' , dataElement , ignore.case = TRUE ) ,
        dataSet = factor( dataSet ), 
        aggregationType = factor( aggregationType ) ,
        valueType = factor( valueType ) ,
        domainType = factor( domainType )
    
    ) 

  count( d, dataSet, categoryCombos,  periodType, timelyDays  )  %>% pander

    
# TODO: add in indice of %OU associated with each dataset
# TODO: add in data Element Groups 

# glimpse(d)

```

## All dataElements within all dataSets


```{r display_dataElement_dataSets}

      
datatable( d %>%
    select( dataSet, dataElement, Malaria, patients, category, categoryCombos, 
            zeroIsSignificant , aggregationType, valueType , domainType) ,
    
    caption = "Data Elements", 
    filter = 'top', 
    editable = TRUE,
    rownames = FALSE, 
    selection = 'multiple' , 
    extensions = c( 'Buttons', 
                           'FixedHeader'
                           # , 
                           # 'Responsive'
                           ) , 
           options = list( 
               # dom = 't',
               scrollX = TRUE,
               scrollY = TRUE,
               fixedColumns = TRUE ,
               # dom = 'Bfrtip', 
               # buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
               pageLength = 15, fixedHeader = TRUE
               )
           ) 


```


## List of DataSet-dataElement Combinations

```{r count_dataset_in_data, comment=""}

    # display with names
    dsde %>%
        left_join( md$dataSets %>% select( id, name ), 
                   by = c("dataSet"="id")
                   ) %>%
        select( -dataSet ) %>%
        rename( dataSet = name ) %>% 
        left_join( md$dataElements %>% select( id, name ), 
                   by = c("dataElement"="id")
                   ) %>%
        select( -dataElement ) %>%
        rename( dataElement = name ) %>% 
        left_join( md$categoryCombos %>% select( id, name ), 
                   by = c("categoryCombo"="id")
                   ) %>%
        select( -categoryCombo ) %>%
        rename( categoryCombo = name ) %>%
        datatable( rownames = FALSE, 
                   options= list( pageLength = 15 , 
                                  scrollY = TRUE) 
                   )

```

## Dataset reporting malaria


```{r datasets }

   # NB : There may be duplicate rows in de.mal because the same elements belong to multiple groups.
   # Compare with de.mal %>% select(-Group) %>% distinct()
   
   
   # just list of datasets with malaria variables 
   mal.datasets = md$dataSets %>%
       select( id, name, periodType, timelyDays ) %>%
       filter( id %in% d.reported$dataElement ) %>%
       rename( Name = name ) %>%
       arrange( Name ) %>%
       select( Name, periodType, timelyDays, id)
   
   pander( mal.datasets  )
   # %>% 
   #     pander_styling( # bootstrap_options = c("striped", "hover")
   #         ) 
   # %>%
   #      column_spec(1, bold = T) 
   
   # NB TODO:  Table of data groups (because it is removed from mal.datasets, to avoid duplicates)

```

## Assigned Organisation Units
 
```{r}

  dataset.ous = md$dataSets %>% 
    select( id, name ) %>%
    # filter( name %in% unique( mal.datasets$dataset.name ) ) %>%
    mutate(
        ou = map( id, ~md$dataSets[  md$dataSets$id==.x , ]$organisationUnits ) ,
        num.ou = map_int( ou , ~length( flatten( .x[[1]] ) ) )
    ) %>%
    select( -ou )

```
 


## Are any dataElements in more than one dataSet?

```{r dE_in_more_than_one_dataset}

  # data frame of datasets and data elements
  dsde = map_df( 1:length(md$dataSets$dataSetElements), 
            ~map_df( md$dataSets$dataSetElements[[.x]], 
                     ~as.matrix(.x) )) %>%
    rename( dataElement.id = dataElement , 
            dataSet.id = dataSet ) %>%
    left_join( md$dataElements %>% select( id, name ) ,
               by = c('dataElement.id' = 'id' )) %>%
    rename( dataElement = name ) %>%
    left_join( md$dataSets %>% select( id, name ) ,
               by = c('dataSet.id' = 'id' )) %>%
    rename( dataSet = name )

  gt1datset = dsde %>% 
      select( dataElement.id, dataElement, dataSet )  %>%
      group_by( dataElement.id , dataElement ) %>%
      summarise( 
          n_dataSets = n_distinct( dataSet ) ,
          dataSets = paste( dataSet, collapse = "; ")
          )  %>%
      filter( n_dataSets > 1) %>%
      arrange( n_dataSets, dataElement ) 
  
  cat( "There are" , nrow( gt1datset) %>% comma , "data elements assigned to more than one dataset." )
  
  datatable( gt1datset )

```


# Indicators  {.tabset .tabset-fade} 


```{r indicators}

indicators = md$indicators

malaria_terms = 'malaria palu RDT TDR IPT ACT ASAQ AL APT PTI SP slide fever fiev'

malaria_search_terms = unlist(stri_extract_all_words(malaria_terms))

# add '\\<' so that only whole word is found
malaria_search_terms_words = paste0( '\\<', malaria_search_terms, '\\>')

mal_indicators = grepl( paste(malaria_search_terms, collapse = '|'), indicators$displayName )

mal_indicators_n = sum( mal_indicators )

```

## There are `r nrow(indicators)` indicators.  Of these, `r mal_indicators_n` have a malaria seach term that includes: `r paste( malaria_terms) `.

```{r}
 pander( indicators, filter = 'top' )
```


<!-- TODO : definitions for indicators  -->


