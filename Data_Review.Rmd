---
output:
  html_document:
    # css: custom.css
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
params:
  dhis_instance: Nigeria
  data_directory:  ../DHIS2
  output_directory: ./ # bug: only uses current directory
  cache: FALSE
  echo: FALSE
---

# **`r params$dhis_instance`** {.tabset .tabset-fade}
<!-- load libraries... -->

```{r packages, message=FALSE, include= FALSE }

# list of required packages
    package.list = c( "openxlsx", "readxl" , "rlist", "knitr", "kableExtra", "xts", "leaflet", "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "scales", "RcppRoll", "zoo", "gridExtra", "futile.logger", "zoo" , "broom" , "Hmisc", "plotly" , "skimr", "tidyverse" )

# Function to test if package is installed 
    pkgTest <- function( package.list = package.list ){
        
        missing.packages = setdiff( package.list , rownames(installed.packages())) 
        if ( length( missing.packages ) > 0 ) install.packages( missing.packages ) 
    }


# Test if packages loaded
    pkgTest( package.list )

# load the packages
    lapply( package.list, suppressMessages( require ) , character.only = TRUE)


knitr::opts_chunk$set( echo = params$echo ,
                       fig.width =  8, 
                       # knitr.table.format = "html" ,
                       cache = params$cache # TRUE for testing; FALSE for production
                       )

```

<!-- ...functions for fetching metadata -->

```{r sources }

source('dhis2_functions.R')

    
    data_directory = params$data_directory
    dhis_instance = params$dhis_instance
    output_directory = getwd() # params$output_directory
  
  # folder for storing review data

  origin.folder = paste0( data_directory , "/" ,
                          dhis_instance , "/")
  
 # login shortcuts

login_origin = function(){
    source( 
    paste0( origin.folder, 
            tolower( params$dhis_instance) , 
            "_login" )
    )

  loginDHIS2( baseurl, username, password)
}
  
```


```{r all_meta }

  meta_data_file = paste0( origin.folder ,
                           dhis_instance, 
                           "_metadata.rds" )

  if ( !file.exists( meta_data_file) ){
   
    # login in to server
    login_origin()
  
    md = metadataDHIS2( baseurl, 'all' )
    
    # glimpse( md )
    
    write_rds( md, meta_data_file )
    
  } else {
      
       md = read_rds( meta_data_file )
  }

  # re-order alaphabetically to be easier to browse in View
  md = md[order(names(md))]
  
  # Retrieve access data 
  date_metadata = file.info( meta_data_file )$ctime 
  
```

Data from selected data will be downloaded for the period 2013-2017, from all organizational units, as totals and details (with categoryOptionCombos).



```{r date_strings }

 # Function to create string of dates
  date_code = function( years = 2013:2017 , months = 1:12 ){
    period = character()
    
    for (year in years ){
      for (month in seq_along(months)){
        this_period = paste0( ";", 
                         year , 
                         ifelse( month < 10 , paste0("0", month) , month )
        )
        period =  c(period, this_period )
      }
    }
    
    # remove first ;
    period =  paste( period, collapse = "")
    period = substring( period, 2, nchar(period))
    
    return( period )
  }
 
  periods = date_code() # default: 2013-2017
  # periods = date_code( 2017, 1 ) # January 2017 only
  
  # as character vector
  periods.vector = strsplit( periods, ";" , fixed = TRUE )[[1]]

  
```



```{r ou_levels}

  # levels
      levels = character()
      for ( i in seq_along( md$organisationUnitLevels$id) ){
    
        levels =  c(levels, paste0("LEVEL-", i) )
      }
      
      levels = paste( levels, collapse = ";")
  
  # import month by month
  levels.vector = strsplit( levels, ";" , fixed = TRUE )[[1]]
  
```



# Data elements {.tabset .tabset-fade}


```{r data_elements_include }

    de.review.xlsx = paste0( output_directory , "/" ,
                             dhis_instance , "/" ,
                             dhis_instance , "_" , 
                             "dataElements.xlsx" ) 


    de.include = readxl::read_xlsx( de.review.xlsx  ) %>% 
        filter( !is.na(Include) ) %>% 
        distinct( dataElement, .keep_all = TRUE )

    # divide elements into smaller parts
    
    # split elements into group of 50 
    section.size = 1
    de.names.sections = ceiling( length( de.include$Include ) / section.size )

    de.name.part = list()
    for ( section in 1:de.names.sections){
        start = (section-1)*section.size + 1
        if (section == 1 ) start = 1
        stop = (section)*section.size 
        if (stop > length(de.include$Include) ) stop = length(de.include$Include)
        
        de.name.part[[section]] = de.include$dataElement[ start:stop ] 
    }

```


## DataElements : Totals 

```{r data_total }
  
    data.totals.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_totals.rds" )

    if ( file.exists( data.totals.file ) ){
        
          data_totals = readRDS( data.totals.file ) 
          
# TODO: check for missing dates, then update 
          
    } else {
            
        data_totals = api_data()
        
        print( paste( "TOTAL:", 
                       scales::comma( nrow( data_totals ) ) , 
                       "records"  ) )

        # save data
        saveRDS( data_totals, data.totals.file )
 
    }

    # get date
    data_totals_date = file.info(data.totals.file)$mtime

```


```{r fetch_data_values_total, eval= FALSE }

  data.totals.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_totals.rds" )

    if ( file.exists( data.totals.file ) ){
        
          data_totals = readRDS( data.totals.file ) 
          
# TODO: check for missing dates, then update 
          # - make fetch into a function usable for totals, details, and datasets...
                                
          
    } else {
  
      # login in to server
      retry( login_origin() )
      
      # import month by month
      
      data = list()
      for ( i in seq_along(periods.vector ) ){
    
         print( paste( periods.vector[i] ) )
        
        data.level = list()
        for ( level in seq_along( levels.vector ) ){
          
          print( levels.vector[level] )
            
            data.de = list()
            for ( part in  seq_along(de.include$Include) ){
                      
                # data elements:
                de.ids = paste( 
                            md$dataElements %>% 
                            select( id, name ) %>%
                            filter( trimws(name) %in% de.name.part[[ part ]] ) %>%
                            .$id ,
                            collapse  = ";" )
 
                print( paste( periods.vector[i], levels.vector[level] , 
                              'part', part , "/" , de.names.sections, 
                              ":" , de.name.part[[ part ]] ) 
                       )
      
                #Assemble the URL ( before starting, double check semicolons for dx dimension )
                url <- paste0( baseurl, "api/analytics/dataValueSet.json?" ,
                      "&dimension=ou:", levels.vector[level] , 
                      "&dimension=pe:" , periods.vector[i] ,
                      "&dimension=dx:" , 

                      # malaria
                      de.ids ,
                      # opd summary
                      # "KNrK5VWTZkx;NLKRV7bYbVy" , # population
                      "&displayProperty=NAME")
      
                # Fetch data
                fetch <- retry( get(url)[[1]] ) # if time-out or other error, will retry 
                
                # if returns a data frame of values (e.g. not 'server error'), then keep
                if ( is.data.frame( fetch ) ){ 
                    
                        data.de[[ part ]] = fetch 
                        print( paste( nrow(fetch), "records. " ) )
                    }
            }
            
            data.level[[level]] = data.table::rbindlist( data.de, fill = TRUE )
            
            print( paste( "Level" , level , "has" , 
                          scales::comma( nrow( data.level[[level]] ) ) , 
                                         "records"  ) ) 
    
        }
        
        # combine level data
        data[[i]] = data.table::rbindlist( data.level , fill = TRUE )
    
        print( paste( "Period has", 
                      scales::comma( nrow( data[[i]] ) ) , 
                      "records"  ) )
  
    }
      
      # combine period data
      data_totals = data.table::rbindlist( data , fill = TRUE)
      
      print( paste( "TOTAL:", scales::comma( nrow( data_totals ) ) , 
                    "records"  ) )
      
    # save data
    saveRDS( data_totals, data.totals.file )
 
    }

    # get date
    data_totals_date = file.info(data.totals.file)$mtime

    # glimpse( data_totals ) 

```

The totals data, `r scales::comma( nrow( data_totals ) )` records,  was downloaded on `r data_totals_date`.


```{r count_dataElements_in_data, comment="" }

  # List data elements by name
  data_totals %>% 
    # names of data elements
    left_join( select(md$dataElements, id, name) ,
                      by = c("dataElement" = "id")
                      ) %>%
    select( -dataElement ) %>% 
    rename( dataElement = name ) %>%
    # summarise reports by dataElement
    group_by( dataElement) %>% 
    summarise( 
        Reported = n() ,
        orgUnits = n_distinct( orgUnit ) ,
        First =  as.yearmon( min( period ), "%Y%m") %>% format(., "%b-%Y"),
        Last = as.yearmon( max( period ), "%Y%m") %>% format(., "%b-%Y")
        ) %>% 
    arrange( -Reported ) %>%
    mutate( Reported = comma( Reported ), 
            orgUnits = comma( orgUnits ) 
            ) %>%

    datatable( rownames = FALSE, options= list( pageLength = 15, scrollY = TRUE ) )


```

## Describe data elements

```{r describe_totals}

   dt = data_totals %>%
        left_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name ) 

    # spread data so that each column is a variable; keep only numeric cols
    df = dt %>% 
        # select( orgUnit, period,  element_combo, value ) %>%
        mutate( value = as.numeric( value ), 
                year = substr(period, 1,4) ) %>%
        select( period, year , orgUnit, value, de.name ) %>%
        spread( de.name, value  ) 
    
    
    skim( df )
    
    # glimpse(df) 
    
 # html( describe( df ) ,  
 #       # condense=c('extremes', 'frequencies', 'both', 'none') ,
 #       size=100, 
 #       scroll=FALSE)
 
 # p = plot( df )
 # htmltools::tagList( p )
 
 # other histogram options...
 
 # df. = map_df( colnames(df), ~filter(df, !.x==0 ) %>% mutate_if(is.numeric, log) )
 # 
 # with( df., histboxp(x= `105-1.3 OPD Malaria (Total)` , group = year, 
 #                     gmd = FALSE, sd=FALSE, bins = 2000)
 #       )
 # 
 # with( df., histboxp(x= .x , group = year, 
 #                     gmd = FALSE, sd=FALSE, bins = 2000)
 #       )
 
```

Alternative describe with skimr

```{r skimr}
 skim( df ) %>% kable
```

## DataElements : Details

```{r fetch_data_values_details, eval=FALSE }

  data.details.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_details.rds" )

    if ( file.exists( data.details.file ) ){
        
          data_details = readRDS( data.details.file ) 
                                
          
    } else {

      # login in to server
      retry( login_origin() )
      
      
      # initialise lists
      data = list()
      data.level = list()
      data.de = list()
      
    # import month by month , level, and data element
      for ( i in seq_along( periods.vector) ){ 
    
          print( paste( periods.vector[i] ) )
        
        for ( level in seq_along( levels.vector ) ){
          
          print( levels.vector[level] )
            
            for ( de.section in 1:de.names.sections ){
                
              # data elements to get:
                de.index =  md$dataElements$name %in% de.name.part[de.section][[1]] 
    
                # data.frame of dataElement-id and categorycomb0-id
                de.catCombo = data_frame( 
                    dataElement = md$dataElements$id[ de.index ] ,
                    dataElement.name = md$dataElements$name[ de.index ] ,
                    categoryCombo = md$dataElements$categoryCombo$id[ de.index ] 
    )
    
                # CategoryOptions for each categoryCombo
                catOptCombos =  data_frame( 
                    categoryOptionCombo = md$categoryOptionCombos$id ,
                    categoryCombo = md$categoryOptionCombos$categoryCombo$id
                )
                
                de.catOptCombo = de.catCombo %>% 
                    inner_join( catOptCombos , by = "categoryCombo")
                
                # string to paste in to data request    
                de.ids = paste( paste0( de.catOptCombo$dataElement, "." , 
                                        de.catOptCombo$categoryOptionCombo) ,
                                collapse  = ";" )

                print( paste( periods.vector[i], levels.vector[level] , 
                              'part', de.section , "/" , de.names.sections) 
                       )
                
                
      
        #Assemble the URL ( before starting, double check semicolons for dx dimension )
        url <- paste0( baseurl, "api/analytics/dataValueSet.json?" ,
                      "&dimension=ou:", levels.vector[level] , 
                      "&dimension=pe:" , periods.vector[i] ,
                      "&dimension=dx:" , 

                      # malaria
                      de.ids ,
                      # opd summary
                      # "KNrK5VWTZkx;NLKRV7bYbVy" , # population
                      "&displayProperty=NAME")
      
                # Fetch data
                fetch <- retry( get(url)[[1]] ) # if time-out or other error, will retry 
                
                # if returns a data frame of values (e.g. not 'server error'), then keep
                if ( is.data.frame( fetch ) ){ 
                    data.de[[de.section]] = fetch
                    
                } else {
                    data.de[[ de.section ]] = data_frame( NA )
                }
            }
            
            data.level[[level]] = data.table::rbindlist( data.de, fill = TRUE )
            
            print( paste( scales::comma( nrow( data.level[[level]] ) ) , "level records"  ) )
        }
          
    # combine level data
    data[[i]] = data.table::rbindlist( data.level, fill = TRUE )
    
        print( paste( scales::comma( nrow( data[[i]] ) ) , "period records"  ) )
    
    }
  
      # combine period data
      data_details = data.table::rbindlist( data , fill = TRUE)
      
      print( paste( "TOTAL:", scales::comma( nrow( data_details ) ) , "total records"  ) )
    
      # save data file           
      saveRDS( data_details, data.details.file )
}
      
    # glimpse( data_details ) 
    
    data_details_date = file.info(data.details.file)$mtime
    
```

```{r data_details}
## DataElements : details 

    data.details.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_details.rds" )

    if ( file.exists( data.details.file ) ){
        
          data_details = readRDS( data.details.file ) 
          
# TODO: check for missing dates, then update 
          # - make fetch into a function usable for details, details, and datasets...
                                
          
    } else {
            
        data_details = api_data( details = TRUE )
        
        # save data
        saveRDS( data_details, data.details.file )
 
    }

    # get date
    data_details_date = file.info( data.details.file )$mtime

```


The detailed data was downloaded on `r data_details_date`

Summarise data details values by dataElement_categoryOptionCombo 

```{r summarise_data_variables }
   dd = data_details %>%
        inner_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name )  %>%
        inner_join( md$categoryOptionCombos %>% select( id , name ) ,
                    by = c( 'categoryOptionCombo' = 'id' ) ) %>%
        rename( cat.name = name )  %>%
        unite( element_combo , de.name, cat.name )

    # spread data so that each column is a variable; keep only numeric cols
    df = dd %>% 
        # select( orgUnit, period,  element_combo, value ) %>%
        mutate( value = as.numeric( value )) %>%
        spread( element_combo, value  ) %>%
        purrr::keep(is.numeric)
    
    skim( df )
    
    # # glimpse(df) 
    # 
    # do.call( data.frame , 
    #        list(Element = names(df ) ,
    #             mean = map_dbl( df , ~round( mean( .x , na.rm = TRUE ) ) ) ,
    #             sd = map_dbl(df , ~round( sd( .x , na.rm = TRUE) ) ) ,
    #             median = map_dbl(df  , median, na.rm = TRUE) ,
    #             min = map_dbl(df , min, na.rm = TRUE) ,
    #             max = map_dbl(df  , max, na.rm = TRUE) ,
    #             n = map_dbl(df  , length) ,
    #             nmiss =  map_dbl(df , ~sum( is.na(.x) ) )
    #        )) %>%
    #     mutate_if( is.numeric , comma ) %>% 
    #     datatable( rownames = FALSE , options = list( pageLength = 15) )
    # 
    # 
```



## Verify:  Sum of data-details equals data-totals

The following table is sorted by the difference between sums for each variable.

```{r verify_details_total }

    sum_details = data_details %>%
        group_by( dataElement ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        group_by( dataElement ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, by = 'dataElement' ) %>%
        left_join( md$dataElements %>% select( id, name ) , 
                   by = c( 'dataElement' = 'id' ) 
                   ) %>%
        select( dataElement, name, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma ) %>%
        datatable()
    
```

Why are some totals > than sum of details/categories? (only evaluate if there is problem verify that sum(details) = totals)

```{r, eval = FALSE}

# summarise and compare by period

    # choose data element to examine
    de = 'GOXEXTR0uST'

# Compare by month
    sum_details = data_details %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' ) 
               ) %>%
        select( period, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma )
    
# Compare by month, orgUnit
    sum_details = data_details %>%
        filter( dataElement %in% de )  %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    compare = left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' , 'orgUnit' ) 
               ) %>%
        left_join( md$organisationUnits %>% select( id, name ) ,
                   by = c( 'orgUnit' = 'id' ) ) %>%
        select( period, orgUnit, name, sum_details,  sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma ) 
    
    compare %>% filter( difference > 0 ) %>% View
    
    count( compare %>% filter( difference > 0 ), period ) %>% print( n = 100 )
    
    # look at details...
    data_details %>% 
        select(dataElement,period, orgUnit, categoryOptionCombo, value) %>%
        filter( dataElement %in% de, 
                period %in% '201506',
                orgUnit %in% (compare %>% filter( difference > 0 ) %>% .$orgUnit) ) %>%
        spread( categoryOptionCombo, value ) %>%
        left_join( compare ) %>%
        View
```



# Data Sets {.tabset .tabset-fade}

## Dataset Submission 

Values shown are for the periods from `r min(periods.vector)` to `r max(periods.vector)`.

## Data elements associated with datasets (all combinations)

```{r dsde }

  # data frame of datasets (ds) and data elements (de)
  dsde = map_df( 1:length(md$dataSets$dataSetElements), 
            ~map_df( md$dataSets$dataSetElements[[.x]], 
                     ~as.matrix(.x) ))


    # Data elements in data.totals
    de = data_totals %>% select( dataElement ) %>% distinct 
    
    # display with names
    datasetsWithDE = dsde %>%
        left_join( md$dataSets %>% select( id, name ), 
                   by = c("dataSet"="id")
                   ) %>%
        select( -dataSet ) %>%
        rename( dataSet = name ) %>% 
        left_join( md$dataElements %>% select( id, name ), 
                   by = c("dataElement"="id")
                   ) %>%
        select( -dataElement ) %>%
        rename( dataElement = name ) %>% 
        left_join( md$categoryCombos %>% select( id, name ), 
                   by = c("categoryCombo"="id")
                   ) %>%
        select( -categoryCombo ) %>%
        rename( categoryCombo = name ) 
        
        datatable( datasetsWithDE , rownames = FALSE,
                   options= list( pageLength = 15 ,
                                  scrollY = TRUE)
                   ) 

  
```



```{r fetch_dataset_completeness , eval = FALSE }

  dataset.file = paste0( origin.folder , 
                     dhis_instance,  
                     "_datset_submission.rds" )

    # open if already exists 
    if ( file.exists( dataset.file ) ){
        
          dataset = readRDS( dataset.file )  %>% as.tibble 
          
    } else {
    
    reports = c( 'ACTUAL_REPORTS', 'ACTUAL_REPORTS_ON_TIME', 'EXPECTED_REPORTS' )
      
    # login in to server
      retry( login_origin() )
      
    # Make list of datasets that associated with downloaded data elements
    datasets =  data_totals %>% 
         # link datasets
        inner_join( dsde , by = "dataElement" 
                          ) %>%
        count( dataSet ) %>% .$dataSet
      
    # initialise listts
      dataset.data = list()
      dataset.level = list()
      
      # fetch by level for each dataset
      for ( i in seq_along( datasets ) ){
    
          print( paste( datasets[i] ) )
        
        for ( level in seq_along( levels.vector ) ){
          
          print( levels.vector[level] )
      
        #Assemble the URL ( before starting, double check semicolons for dx dimension )
        url <- paste0( baseurl, "api/analytics/dataValueSet.json?" ,
                      "&dimension=ou:", levels.vector[level] , 
                      "&dimension=pe:" , paste( periods.vector, collapse = ';') ,
                      "&dimension=dx:" , 
                      paste0( datasets[i], ".", reports , collapse = ';')
                       ,
                      "&displayProperty=NAME")
      
        # Fetch data
        fetch <- retry( get(url)[[1]] ) # if time-out or other error, will retry 
        
        # if returns a data frame of values (e.g. not 'server error'), then keep
        if ( is.data.frame( fetch ) )  dataset.level[[level]] = fetch
        
        } 
        
    # combine level data
    dataset.data[[i]] = data.table::rbindlist( dataset.level )
    
        print( paste( scales::comma( nrow( dataset.data[[i]] ) ) , "records"  ) )
    
    }
  
      # combine period data
      dataset = data.table::rbindlist( dataset.data ) %>% as.tibble
      
      print( paste( "TOTAL:", scales::comma( nrow( dataset) ) , "records"  ) )
    
      # glimpse(data)
      
      saveRDS( dataset, dataset.file )
    }

    dataset.data = dataset %>% 
        separate( col = dataElement , 
                  into = c('dataSet', 'Category' ), 
                  sep = "\\.") %>%
        inner_join( md$dataSets , 
                    by = c( 'dataSet' = 'id') ) %>% 
        rename( dataSet = name , dataSet.id = dataSet) %>%
        count( dataSet, Category ) %>%
        spread( Category, n )
        
    # glimpse( dataset.data )
    
    kable( dataset.data )
        

```

```{r dataset_submissions }
## DataElements : details 

  dataset.submission.file = paste0( origin.folder , 
                     dhis_instance,  
                     "_datset_submission.rds" )


    if ( file.exists( dataset.submission.file ) ){
        
          data_submissions = readRDS( dataset.submission.file ) 
          
# TODO: check for missing dates, then update 
          # - make fetch into a function usable for details, details, and datasets...
                                
          
    } else {
            
        data_submissions = api_data( submissions = TRUE )
        
        # save data
        saveRDS( data_submissions, dataset.submission.file )
 
    }

    # get date
    data_submissions_date = file.info( dataset.submission.file )$mtime

```

## Submissions 

- Dataset 'completeness' (better described as submission)

```{r metaDataLabel_function , eval = FALSE }

metaDataLabel = function( df, .col , md ){
    
    lhs = 'orgUnit'
    rhs = 'id'
    
    y = md %>% select( id, name ) 
    
    d = df %>% left_join( y , by = c( lhs = rhs ) )
    
    
    return(d)
    
    x_df <- data_frame(id_x = 1:10, x = rnorm(10))
    y_df <- data_frame(id_y = 1:10, y = rnorm(10))

    id_x = 'id_x'
    id_y = 'id_y'

    x_df  %>%  inner_join( y_df , by = c( id_x = id_y ))
    
    
    x_df <-  data_totals[1:100, ] $>$ as.tibble()
    
    x_df <-  data_frame( orgUnit = data_totals %>%  filter( !is.na(orgUnit) ) %>% .$orgUnit )
                         
    y_df <- data_frame(id =  md$organisationUnits %>% .$id )

    id_x = 'orgUnit'
    id_y = 'id'
    
    x_df[1:100,]  %>%  inner_join( y_df , by = c( id_x = id_y )) 
    
    x_df  %>%  inner_join( x_df[1:100,] , by = c( id_x = id_x ))
    
    y_df  %>%  inner_join( y_df , by = c( id_y = id_y ))


}

metaDataLabel( df =  data_totals[1:100, ], .col = 'orgUnit' , md = md$organisationUnits)

```

### Submissions with dataElements (totals) by OrgUnit Level

Table of number of org units that provided data for each data element, stratified by dataset (row headings) and orgUnit level (column headings).  

<!-- What would be really cool--to show number of orgunits available, assigned to dataset, and actually submitted data for each dataset/data element. -->

```{r Submission_de_Totals }


 d = data_totals  %>% 
    
    # Remove any rows with all missing data
    select( -starts_with( 'NA' ) ) %>%
    filter( complete.cases(.) ) %>%
    
    # get ou level 
    left_join(
        select( ous , id, level ) , 
        by = c('orgUnit' = 'id')
    ) %>% 
    
    # join dataset to dataElement
    left_join( dsde, by = 'dataElement' ) %>%
    group_by( dataSet, dataElement , level ) %>%
    summarise( n = n_distinct( orgUnit ) )   %>%
    ungroup %>%
     
    #dataset name
    rename( id = dataSet ) %>%
    left_join( md$dataSets %>% select( id, name ) ,  by = 'id'  ) %>%
    rename( dataSet = name ) %>%
    select( -id ) %>%
     
    # data element name
    rename( id  = dataElement ) %>%
    left_join( md$dataElements %>% select( id, name ) , by = 'id' ) %>%
    rename( dataElement = name ) %>%
    select( -id ) %>%
     
    spread( level, n ) 
 
 kable( d, 'html' ) %>% 
       kable_styling(bootstrap_options = c("striped", "hover") ) %>%
        column_spec(1, bold = T) 
```

### Submissions with dataElements (totals)

```{r Submission_de_details }

    s = dataset %>%
        separate( dataElement, 
                  c('dataElement.id', 'Category' ), sep = '\\.' 
                  ) %>%
        left_join(  ous %>% select( id, level ) , 
                    by = c('orgUnit' = 'id') ) %>%
        group_by( level, period , dataElement.id , Category ) %>%
        summarise( value = sum( as.integer( value) ) ) %>%
        ungroup() %>% 
        spread( Category, value ) %>%
        mutate( 
            submitted = ACTUAL_REPORTS / EXPECTED_REPORTS ,
            onTime = ACTUAL_REPORTS_ON_TIME / EXPECTED_REPORTS 
            ) %>%
         # level names
         left_join( 
             select( md$organisationUnitLevels, level, name  ), 
             by = 'level' 
             ) %>%
        mutate( 
            name = fct_reorder( name, level )
        ) %>%
        rename( level.name = name ) %>%
    
        # data element names 
        left_join( 
            select( md$dataSets, id, name ) %>% 
            rename( dataElement.id = id , dataset = name ) ,
            by = 'dataElement.id' 
            )

    # convert month-Yr to date
    s$date = fast_strptime( as.character(  s$period ) , "%Y%m") %>% as.POSIXct()
  
    # summary( s$submitted )
  

```


```{r submission_charts}

# expected number
    ggplot(s,  aes(x = date, y = EXPECTED_REPORTS, 
                   group = level.name , color = level.name )) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_wrap( ~ dataset, scales  = 'free' ,
                labeller = label_wrap_gen(width = 25, multi_line = TRUE)
                ) +
    labs( title = 'Expected reports by level', 
             subtitle =  '' ,
             caption = params$origin_login_file
             ) 
    
    # ggplotly( g )

# Actual number
    ggplot(s,  aes(x = date, y = ACTUAL_REPORTS, 
                   group = level.name , color = level.name )) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_wrap( ~ dataset, scales  = 'free' ,
                labeller = label_wrap_gen(width = 25, multi_line = TRUE)
                ) +
    labs( title = 'Actual reports by level', 
             subtitle =  '' ,
             caption = params$origin_login_file
             ) 
    
# submission rate
    ggplot(s,  aes(x = date, y = submitted, 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_wrap( ~ dataset, scales  = 'free' ,
                labeller = label_wrap_gen(width = 25, multi_line = TRUE)
                ) +
    labs( title = 'Dataset submission rate by level', 
             subtitle =  'denominator is expected reports' ,
             caption = params$origin_login_file
             )
    
# onTime rate
    ggplot(s,  aes(x = date, y = onTime, 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_wrap( ~ dataset, scales  = 'free' ,
                labeller = label_wrap_gen(width = 25, multi_line = TRUE)
                ) +
    labs( title = 'Dataset submission-on-time rate, by level', 
             subtitle =  'denominator is expected reports' ,
             caption = params$origin_login_file
             )
    
```


## Data element completeness

Completeness by element, level: 

- crude measure with denom = all orgunits

link with org units 

```{r ous_metatdata }

    feature_type = function( coordinate ){
        n = length( gregexpr( '[' , coordinate , fixed = TRUE)[[1]] )
        
        if ( is.na( coordinate ) ) return(NA)
        if (n==1) return('Point') 
        if (n>1) return('Polygon') 
        
    
    }

  ous = md$organisationUnits %>% 
    select( id, name, path , featureType, 
            # active , # is not available in all API ?
            openingDate, closedDate ) %>%
    mutate( level = map_dbl( path, 
                           ~length( gregexpr("/", .x, perl = TRUE)[[1]]) 
                           ) 
    )
  
 
```

```{r completeness_crude }
  
  d.ous = dataset %>% 
        separate( col = dataElement , 
                  into = c('dataSet', 'Category' ), 
                  sep = "\\.") %>%
        inner_join( md$dataSets , 
                    by = c( 'dataSet' = 'id') ) %>% 
        rename( dataSet = name , dataSet.id = dataSet) %>% 
        inner_join( ous, 
                    by = c( 'orgUnit' = 'id' ) 
                        ) 
    
    
                     
  s = d.ous  %>%
    mutate( 
        name = fct_reorder( name, level )
        ) %>%
    rename( dataElement.id = dataElement , 
            level.name = name ) %>%
    group_by( period, level, level.name , dataElement.id ) %>%
    summarise( report = n() )  %>% 
    left_join( count( ous, level ) , by = 'level' ) %>%
    mutate( completeness = report / n ) %>%
    ungroup() %>%
    # data element names 
    left_join( 
        select( md$dataElements, id, name ) %>% 
            rename( dataElement.id = id , dataElement = name ) ,
        by = 'dataElement.id' 
    )
  
  # convert month-Yr to date
  s$date = fast_strptime( as.character(  s$period ) , "%Y%m") 
  
  summary( s$completeness )
  
    ggplot(s,  aes(x = date, y = completeness, 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_wrap( ~ dataElement, 
                labeller = label_wrap_gen(width = 35, multi_line = TRUE)
                ) +
    labs( title = 'Crude completeness by data element', 
             subtitle =  'denominator is current number of all org units' ,
             caption = params$origin_login_file
             )
  
```

- Summarise org units open each period

Limitation: Because only one openiningDate is recorded, if clinic was closed, then reoppened, it will be reported as if it was always open.  


```{r open_orgs}
 
 
    # convert month-Yr to date
  d = ous.n %>%
      # level names
      left_join( 
          select( md$organisationUnitLevels, level, name  ) , 
          by = 'level' ) %>%
    mutate( 
        name = fct_reorder( name, level )
        )

  d$date = fast_strptime( as.character(  d$period ) , "%Y%m") 
  
  ggplot( d,  aes(x = date, y = n, group = level )) + 
      geom_line() +
      facet_wrap( ~name , scales = 'free' )
  

  
```

<!-- NB:  Use API to save charts as favorites??? -->

<!-- Compare with indicators from other programs--tb, hiv, imm... -->

# Field visits

- site selection options
