---
output:
  html_document:
    # css: custom.css
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
params:
  dhis_instance: Sierra Leone Demo
  data_directory:  
  output_directory: ./ # bug: only uses current directory
  cache: FALSE
  echo: FALSE
---

# **`r params$dhis_instance`** {.tabset .tabset-fade}
<!-- load libraries... -->

```{r packages, message=FALSE, include= FALSE, warning= FALSE }

# list of required packages
    package.list = c( "openxlsx", "readxl" , "rlist", "knitr", "kableExtra", "xts", "leaflet", "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "scales", "RcppRoll", "zoo", "gridExtra", "futile.logger", "zoo" , "broom" , "Hmisc", "plotly" , "skimr", "tidyverse" )

# Function to test if package is installed 
    pkgTest <- function( package.list = package.list ){
        
        missing.packages = setdiff( package.list , rownames(installed.packages())) 
        if ( length( missing.packages ) > 0 ) install.packages( missing.packages ) 
    }


# Test if packages loaded
    pkgTest( package.list )

# load the packages
    lapply( package.list, suppressMessages( require ) , character.only = TRUE)


knitr::opts_chunk$set( echo = params$echo ,
                       message = FALSE ,
                       comment = "" ,
                       fig.width =  8, 
                       # knitr.table.format = "html" ,
                       cache = params$cache # TRUE for testing; FALSE for production
                       )

```

<!-- ...functions for fetching metadata -->

```{r sources, include= FALSE }

source('dhis2_functions.R')

    
    data_directory = params$data_directory
    dhis_instance = params$dhis_instance
    output_directory = getwd() # params$output_directory
  
  # folder for storing review data

  origin.folder = paste0( ifelse( is.na( data_directory ), "" , 
                                  paste0( data_directory, "/" ) 
                                  ) ,
                          dhis_instance , "/")
  
 # login shortcuts

login_origin = function(){
    source( 
    paste0( origin.folder, 
            tolower( params$dhis_instance) , 
            "_login" )
    )

  loginDHIS2( baseurl, username, password)
}
  
```


```{r all_meta }

  meta_data_file = paste0( origin.folder ,
                           dhis_instance, 
                           "_metadata.rds" )

  if ( !file.exists( meta_data_file) ){
   
    # login in to server
    login_origin()
  
    md = metadataDHIS2( baseurl, 'all' )
    
    # glimpse( md )
    
    write_rds( md, meta_data_file )
    
  } else {
      
       md = read_rds( meta_data_file )
  }

  # re-order alaphabetically to be easier to browse in View
  md = md[order(names(md))]
  
  # Retrieve access data 
  date_metadata = file.info( meta_data_file )$ctime 
  
```

Data from selected data will be downloaded for the period 2013-2017, from all organizational units, as totals and details (with categoryOptionCombos).



```{r date_strings }

 # Function to create string of dates
  date_code = function( years = 2013:2017 , months = 1:12 ){
    period = character()
    
    for (year in years ){
      for (month in seq_along(months)){
        this_period = paste0( ";", 
                         year , 
                         ifelse( month < 10 , paste0("0", month) , month )
        )
        period =  c(period, this_period )
      }
    }
    
    # remove first ;
    period =  paste( period, collapse = "")
    period = substring( period, 2, nchar(period))
    
    return( period )
  }
 
  periods = date_code() # default: 2013-2017
  # periods = date_code( 2017, 1 ) # January 2017 only
  
  # as character vector
  periods.vector = strsplit( periods, ";" , fixed = TRUE )[[1]]

  
```

```{r ous }  

# Same code as chunk 'ou_and_levels' from Metadata_Review.Rmd

feature_type = function( coordinate ){
    n = length( gregexpr( '[' , coordinate , fixed = TRUE)[[1]] )
    
    if ( is.na( coordinate ) ) return(NA)
    if (n==1) return('Point') 
    if (n>1) return('Polygon') 
    

}

  # levels
  levels = character()
    
  for ( i in seq_along( md$organisationUnitLevels$id) ){
    
        levels =  c(levels, paste0("LEVEL-", i) )
      }
      
  levels = paste( levels, collapse = ";")
  
  levels.vector = strsplit( levels, ";" , fixed = TRUE )[[1]]


  parse_parent_ous = function( path ){
       breaks = gregexpr("/", path , perl = TRUE)[[1]]
       n = length( breaks ) 
       if ( n == 0 ) return( NA ) 
       if ( n == 1 ) return( substr( path , breaks[1] + 1 , length(path) ) ) 
       substr( path , breaks[n-1] + 1 , breaks[n]-1 )
  }
  
   ous =  md$organisationUnits %>% 
        select( id, path, name, shortName, coordinates , 
                created, lastUpdated, ends_with('Date') 
                ) %>% as.tibble %>%
       rename( ous = name ) %>%
        mutate( 
          ous = ifelse( ous %in% "", shortName, ous ) , #if name blank, use shortName
          level = map_chr( path, 
                               ~length( gregexpr("/", .x, perl = TRUE)[[1]]) 
                               ) ,
          parent.id =  map_chr( path, ~parse_parent_ous( .x ) ) ,
          feature = map_chr( coordinates, ~feature_type(.x ) )
        ) %>%
       # Name of parent
       left_join( md$organisationUnits %>% select( id, name ) ,
                   by = c('parent.id' = 'id' ) ) %>%
       rename( parent = name ) %>%
       # Name of level
       left_join( md$organisationUnitLevels %>% select( level, name ) %>%
                      mutate( level = as.character( level ) ),
                  by = 'level' ) %>%
       rename( level.name = name)
    
```

```{r ou_levels}
# levels
      levels = character()
      for ( i in seq_along( md$organisationUnitLevels$id) ){
    
        levels =  c(levels, paste0("LEVEL-", i) )
      }
      
      levels = paste( levels, collapse = ";")
  
  # import month by month
  levels.vector = strsplit( levels, ";" , fixed = TRUE )[[1]]
  
```



# Data elements {.tabset .tabset-fade}


```{r data_elements_include }


    de.review.xlsx = paste0( output_directory , "/" ,
                             dhis_instance , "/" ,
                             dhis_instance , "_" , 
                             "dataElements.xlsx" ) 

    sheets = excel_sheets(de.review.xlsx)
    
    # get selected rows from every spreadsheet tab
    de.include = map_df( seq_along(sheets) , ~readxl::read_xlsx( de.review.xlsx , 
                                                            sheet = .x ) %>% 
        filter( !is.na(Include) ) %>% 
        distinct( dataElement, .keep_all = TRUE )
    )
    
    
    # if none selected, pick intersection of malaria and confirmed 
    if ( nrow( de.include) == 0 ){
        
        de.mal = readxl::read_xlsx( de.review.xlsx , sheet = 'mal' ) %>%
            .$dataElement %>% unique
        
        de.conf = readxl::read_xlsx( de.review.xlsx , sheet = 'conf' ) %>%
            .$dataElement %>% unique
        
        include = intersect( de.mal$dataElement,
                                de.conf$dataElement)
        
        
        de.include = readxl::read_xlsx( de.review.xlsx  ) %>% 
            filter( dataElement %in% include ) %>% 
            distinct( dataElement, .keep_all = TRUE )

    }

```


## DataElements : Totals 

```{r data_total }
  
    data.totals.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_totals.rds" )

    if ( file.exists( data.totals.file ) ){
        
          data_totals = readRDS( data.totals.file ) 
          
# TODO: check for missing dates, then update 
          
    } else {
            
        data_totals = api_data( periods = periods.vector , 
                                levels = levels.vector , 
                                de.vars = de.include ,
                                file = "" ,
                                details = FALSE , 
                                submissions =  FALSE )
        
        print( paste( "TOTAL:", 
                       scales::comma( nrow( data_totals ) ) , 
                       "records"  ) )

        # save data
        saveRDS( data_totals, data.totals.file )
 
    }

    # get date
    data_totals_date = file.info(data.totals.file)$mtime

```


The totals data, `r scales::comma( nrow( data_totals ) )` records,  was downloaded on `r data_totals_date`.


```{r count_dataElements_in_data, comment="" }

  # List data elements by name
  data_totals %>% 
    # names of data elements
    left_join( select(md$dataElements, id, name) ,
                      by = c("dataElement" = "id")
                      ) %>%
    select( -dataElement ) %>% 
    rename( dataElement = name ) %>%
    # summarise reports by dataElement
    group_by( dataElement) %>% 
    summarise( 
        Reported = n() ,
        orgUnits = n_distinct( orgUnit ) ,
        First =  as.yearmon( min( period ), "%Y%m") %>% format(., "%b-%Y"),
        Last = as.yearmon( max( period ), "%Y%m") %>% format(., "%b-%Y")
        ) %>% 
    arrange( -Reported ) %>%
    mutate( Reported = comma( Reported ), 
            orgUnits = comma( orgUnits ) 
            ) %>%

    datatable( rownames = FALSE, options= list( pageLength = 15, scrollY = TRUE ) )


```

## Describe data elements

```{r describe_totals}

   dt = data_totals %>%
        left_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name ) 

    # spread data so that each column is a variable; keep only numeric cols
    df = dt %>% 
        # select( orgUnit, period,  element_combo, value ) %>%
        mutate( value = as.numeric( value ), 
                year = substr(period, 1,4) ) %>%
        select( period, year , orgUnit, value, de.name ) %>%
        spread( de.name, value  ) 
    
    
    skim( df )
    
    # glimpse(df) 
    
 # html( describe( df ) ,  
 #       # condense=c('extremes', 'frequencies', 'both', 'none') ,
 #       size=100, 
 #       scroll=FALSE)
 
 # p = plot( df )
 # htmltools::tagList( p )
 
 # other histogram options...
 
 # df. = map_df( colnames(df), ~filter(df, !.x==0 ) %>% mutate_if(is.numeric, log) )
 # 
 # with( df., histboxp(x= `105-1.3 OPD Malaria (Total)` , group = year, 
 #                     gmd = FALSE, sd=FALSE, bins = 2000)
 #       )
 # 
 # with( df., histboxp(x= .x , group = year, 
 #                     gmd = FALSE, sd=FALSE, bins = 2000)
 #       )
 
```


## DataElements : Details

<!-- TODO: Look at data_totals and decide if details needed -->

```{r data_details}
## DataElements : details 

    data.details.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_details.rds" )

    if ( file.exists( data.details.file ) ){
        
          data_details = readRDS( data.details.file ) 
          
# TODO: check for missing dates, then update 
          # - make fetch into a function usable for details, details, and datasets...
                                
          
    } else {
            
        data_details = api_data( periods = periods.vector , 
                                levels = levels.vector , 
                                de.vars = de.include ,
                                file = "" ,
                                details = TRUE , 
                                submissions =  FALSE )
        
        # save data
        saveRDS( data_details, data.details.file )
 
    }

    # get date
    data_details_date = file.info( data.details.file )$mtime

```


The detailed data was downloaded on `r data_details_date`

Summarise data details values by dataElement_categoryOptionCombo 

```{r summarise_data_variables }
   dd = data_details %>%
        inner_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name )  %>%
        inner_join( md$categoryOptionCombos %>% select( id , name ) ,
                    by = c( 'categoryOptionCombo' = 'id' ) ) %>%
        rename( cat.name = name )  %>%
        unite( element_combo , de.name, cat.name )

    # spread data so that each column is a variable; keep only numeric cols
    df = dd %>% 
        # select( orgUnit, period,  element_combo, value ) %>%
        mutate( value = as.numeric( value )) %>%
        spread( element_combo, value  ) %>%
        purrr::keep(is.numeric)
    
    skim( df )
    
    # # glimpse(df) 
    # 
    # do.call( data.frame , 
    #        list(Element = names(df ) ,
    #             mean = map_dbl( df , ~round( mean( .x , na.rm = TRUE ) ) ) ,
    #             sd = map_dbl(df , ~round( sd( .x , na.rm = TRUE) ) ) ,
    #             median = map_dbl(df  , median, na.rm = TRUE) ,
    #             min = map_dbl(df , min, na.rm = TRUE) ,
    #             max = map_dbl(df  , max, na.rm = TRUE) ,
    #             n = map_dbl(df  , length) ,
    #             nmiss =  map_dbl(df , ~sum( is.na(.x) ) )
    #        )) %>%
    #     mutate_if( is.numeric , comma ) %>% 
    #     datatable( rownames = FALSE , options = list( pageLength = 15) )
    # 
    # 
```



## Verify:  Sum of data-details equals data-totals

The following table is sorted by the difference between sums for each variable.

```{r verify_details_total }

    sum_details = data_details %>%
        group_by( dataElement ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        group_by( dataElement ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, by = 'dataElement' ) %>%
        left_join( md$dataElements %>% select( id, name ) , 
                   by = c( 'dataElement' = 'id' ) 
                   ) %>%
        select( dataElement, name, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma ) %>%
        datatable()
    
```

Why are some totals > than sum of details/categories? (only evaluate if there is problem verify that sum(details) = totals)

```{r, eval = FALSE}

# summarise and compare by period

    # choose data element to examine
    de = 'GOXEXTR0uST'

# Compare by month
    sum_details = data_details %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' ) 
               ) %>%
        select( period, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma )
    
# Compare by month, orgUnit
    sum_details = data_details %>%
        filter( dataElement %in% de )  %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    compare = left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' , 'orgUnit' ) 
               ) %>%
        left_join( md$organisationUnits %>% select( id, name ) ,
                   by = c( 'orgUnit' = 'id' ) ) %>%
        select( period, orgUnit, name, sum_details,  sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma ) 
    
    compare %>% filter( difference > 0 ) %>% View
    
    count( compare %>% filter( difference > 0 ), period ) %>% print( n = 100 )
    
    # look at details...
    data_details %>% 
        select(dataElement,period, orgUnit, categoryOptionCombo, value) %>%
        filter( dataElement %in% de, 
                period %in% '201506',
                orgUnit %in% (compare %>% filter( difference > 0 ) %>% .$orgUnit) ) %>%
        spread( categoryOptionCombo, value ) %>%
        left_join( compare ) %>%
        View
```




# Data Completeness {.tabset .tabset-fade}

## Dataset Submission 

Values shown are for the periods from `r min(periods.vector)` to `r max(periods.vector)`.

```{r dsde }

  # data frame of datasets (ds) and data elements (de)
  dsde = map_df( 1:length(md$dataSets$dataSetElements), 
            ~map_df( md$dataSets$dataSetElements[[.x]], 
                     ~as.matrix(.x) ))


    # Data elements in data.totals
    de = data_totals %>% select( dataElement ) %>% distinct 
    
    # display with names
    datasetsWithDE = dsde %>%
        left_join( md$dataSets %>% select( id, name ), 
                   by = c("dataSet"="id")
                   ) %>%
        select( -dataSet ) %>%
        rename( dataSet = name ) %>% 
        left_join( md$dataElements %>% select( id, name ), 
                   by = c("dataElement"="id")
                   ) %>%
        select( -dataElement ) %>%
        rename( dataElement = name ) %>% 
        left_join( md$categoryCombos %>% select( id, name ), 
                   by = c("categoryCombo"="id")
                   ) %>%
        select( -categoryCombo ) %>%
        rename( categoryCombo = name ) 
        
        datatable( datasetsWithDE , rownames = FALSE,
                   options= list( pageLength = 15 ,
                                  scrollY = TRUE)
                   ) 

  
```


```{r dataset_submissions }
## DataElements : details 

  dataset.submission.file = paste0( origin.folder , 
                     dhis_instance ,  
                     "_dataset_submissions.rds" )

    if ( file.exists( dataset.submission.file ) ){
        
          data_submissions = readRDS( dataset.submission.file ) 
          
# TODO: check for missing dates, then update 
          # - make fetch into a function usable for details, details, and datasets...
                                
          
    } else {
            
        data_submissions = api_data( periods = periods.vector , 
                                levels = levels.vector , 
                                de.vars = de.include ,
                                file = "" ,
                                details = FALSE , 
                                submissions =  TRUE )
        
        # save data
        saveRDS( data_submissions, dataset.submission.file )
 
    }

    # get date
    data_submissions_date = file.info( dataset.submission.file )$mtime

```

## Submissions by OrgUnit Level

- Dataset 'completeness' (better described as submission)

Table of number of org units that provided data for each data element, stratified by dataset (row headings) and orgUnit level (column headings).  

<!-- What would be really cool--to show number of orgunits available, assigned to dataset, and actually submitted data for each dataset/data element. -->

```{r Submission_de_Totals }


 d = data_totals  %>% 
    
    # Remove any rows with all missing data
    filter( complete.cases(.) ) %>%
    
    # get ou level 
    left_join(
        select( ous , id, level ) , 
        by = c('orgUnit' = 'id')
    ) %>% 
    
    # join dataset to dataElement
    left_join( dsde, by = 'dataElement' ) %>%
    group_by( dataSet, dataElement , level ) %>%
    summarise( n = n_distinct( orgUnit ) )   %>%
    ungroup %>%
     
    #dataset name
    rename( id = dataSet ) %>%
    left_join( md$dataSets %>% select( id, name ) ,  by = 'id'  ) %>%
    rename( dataSet = name ) %>%
    select( -id ) %>%
     
    # data element name
    rename( id  = dataElement ) %>%
    left_join( md$dataElements %>% select( id, name ) , by = 'id' ) %>%
    rename( dataElement = name ) %>%
    select( -id ) %>%
     
    spread( level, n ) 
 
 kable( d, 'html' ) %>% 
       kable_styling(bootstrap_options = c("striped", "hover") ) %>%
        column_spec(1, bold = T) 
```

```{r dataset_completeness }
  
  d.ous = data_submissions %>% 
        separate( col = dataElement , 
                  into = c('dataSet', 'Category' ), 
                  sep = "\\.") %>%
        inner_join( md$dataSets %>% select( id, name ) , 
                    by = c( 'dataSet' = 'id') ) %>% 
        rename( dataSet = name , dataSet.id = dataSet) %>% 
        inner_join( ous %>% select( ous, parent, level , level.name , feature, id ), 
                    by = c( 'orgUnit' = 'id' ) 
                        ) 
    
                     
  s = d.ous  %>%
    # mutate( 
    #     ous = fct_reorder( ous, level )
    #     ) %>%
    group_by( period, level, level.name , dataSet , Category ) %>%
    summarise( report = n() )  %>% 
    left_join( count( ous, level ) , by = 'level' ) %>%
    mutate( completeness = report / n ) %>%
    ungroup()
  
  # convert month-Yr to date
  s$date = fast_strptime( as.character(  s$period ) , "%Y%m") %>% as.POSIXct()
  
```

This chart shows the percentage of active organisational units that were expected to report during each period.  Any value less than 100% indicates that some organisational units were not assigned the dataset report.  

```{r expected_reports}
  # summary( s$completeness )
  
    ggplot(s %>% filter( Category %in% "EXPECTED_REPORTS" ),  aes(x = date, y = completeness, 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_grid( Category ~ dataSet, 
                labeller = label_wrap_gen(width = 35, multi_line = TRUE)
                ) +
    labs( title = 'Percent of OrgUnits Expected to Report', 
             subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance ,
          x = "Percent"
             ) +
    scale_y_continuous(labels = scales::percent)
  
```


This chart shows the perecentage of active organisational units that reported, and reported on time, during each period.  Completeness is shown by level, because a report was submitted at upper levels does not indicate the percentage of reports submitted by the lower levels organisation units. **Attention should be given to the lowest level, e.g. health facilities, where data is reported.** 

```{r submitted_reports}
  # summary( s$completeness )
  
if ( s %>% filter( !Category %in% "EXPECTED_REPORTS" ) %>% nrow > 0 ){
    ggplot( s %>% filter( !Category %in% "EXPECTED_REPORTS" ),  aes(x = date, y = completeness, 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_grid( Category ~ dataSet, 
                labeller = label_wrap_gen(width = 35, multi_line = TRUE)
                ) +
    labs( title = 'Crude completeness by data element', 
             subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance
             ) +
    scale_y_continuous(labels = scales::percent)
} else {
    cat("No data available on submitted datasets.")
}
    
```


## Data element completeness

Completeness by element, level: 

- crude measure with denom = all orgunits

```{r Submission_de_details }

    s = data_totals %>%
        left_join(  ous %>% select( id, level, level.name ) , 
                    by = c('orgUnit' = 'id') ) %>%
        count( dataElement , level, level.name , period ) %>% 
        rename( reported = n ) %>%
        left_join( count( ous, level ) , by = 'level' ) %>%
        rename( expected = n ) %>%
        mutate( 
            completeness = reported / expected 
            ) %>%
    
        # data element names 
        rename( id = dataElement ) %>%
        left_join( 
            md$dataElements %>% select( id, name ) , 
            by = c( 'id' ) 
            ) %>%
        rename( dataElement = name )

    # convert month-Yr to date
    s$date = fast_strptime( as.character(  s$period ) , "%Y%m") %>% as.POSIXct()
  
    # summary( s$completeness )
  

```

Subset to organizational unit levels with at least 20 expected reports

```{r submission_charts}



# percent completeness 
    ggplot(s %>% filter(expected >=20 ),  aes(x = date, y = completeness, 
                   group = level.name , color = level.name )) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_wrap( ~ dataElement, 
                labeller = label_wrap_gen(width = 25, multi_line = TRUE)
                ) +
    labs( title = 'Percent completeness by level', 
             subtitle =  '' ,
             caption = params$origin_login_file
             ) +
    scale_y_continuous(labels = scales::percent)
    
    # ggplotly( g )

# Actual number
    ggplot(s %>% filter(expected >=20 ),  aes(x = date, y = reported, 
                   group = level.name , color = level.name )) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_wrap( ~ dataElement,
                labeller = label_wrap_gen(width = 25, multi_line = TRUE)
                ) +
    labs( title = 'Actual reports by level', 
             subtitle =  '' ,
             caption = params$origin_login_file
             ) 
    
```


- Summarise org units open each period

Limitation: Because only one openiningDate is recorded, if clinic was closed, then reoppened, it will be reported as if it was always open.  


<!-- NB:  Use API to save charts as favorites??? -->

<!-- Compare with indicators from other programs--tb, hiv, imm... -->

# Anomalies

This section will be to identify extreme values that are most likely data entry errors.  Some decisions will need to be made about whether to remove or replace those values for the rest of the anlyses. 

Detect outliers/anomalies:  
- WHO Outilier detection
- Anomallize

# Field visits

- site selection options
