---
title: "Desktop Data Review"

output:
  html_document:
    css: custom.css
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
params:
  origin_login_file: Uganda
  data_directory: ../HMIS/DHIS2
  cache: FALSE
  echo: TRUE
---

# **`r params$origin_login_file`** {.tabset .tabset-fade}
<!-- load libraries... -->

```{r packages, message=FALSE, include= FALSE }

# list of required packages
    package.list = c( "openxlsx", "readxl" , "rlist", "knitr", "kableExtra", "xts", "leaflet", "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "scales", "RcppRoll", "zoo", "gridExtra", "futile.logger", "zoo" , "broom" , "tidyverse" )

# Function to test if package is installed 
    pkgTest <- function( package.list = package.list ){
        
        missing.packages = setdiff( package.list , rownames(installed.packages())) 
        if ( length( missing.packages ) > 0 ) install.packages( missing.packages ) 
    }


# Test if packages loaded
    pkgTest( package.list )

# load the packages
    lapply( package.list, suppressMessages( require ) , character.only = TRUE)


knitr::opts_chunk$set( echo = params$echo ,
                       fig.width =  8, 
                       # knitr.table.format = "html" ,
                       cache = params$cache # TRUE for testing; FALSE for production
                       )

```

<!-- ...functions for fetching metadata -->

```{r sources }

source('dhis2_functions.R')

    
origin.folder = paste0( params$data_directory , "/" , params$origin_login_file , "/")

origin_login_file = params$origin_login_file

 # login shortcuts

login_origin = function(){
    source( 
    paste0( origin.folder, 
            tolower( params$origin_login_file) , 
            "_login" )
    )

  loginDHIS2( baseurl, username, password)
}
  
```


```{r all_meta }

  meta_data_file = paste0( origin.folder , 
                           params$origin_login_file, "_metadata.rds" ) 

  if ( !file.exists( meta_data_file) ){
   
    # login in to server
    login_origin()
  
    md = metadataDHIS2( baseurl, 'all' )
    
    # glimpse( md )
    
    write_rds( md, meta_data_file )
    
  } else {
      
       md = read_rds( meta_data_file )
  }

  # re-order alaphabetically to be easier to browse in View
  md = md[order(names(md))]
  
  # Retrieve access data 
  date_metadata = file.info( meta_data_file )$ctime 
  
```


```{r date_strings }

 # Function to create string of dates
  date_code = function( years = 2013:2017 , months = 1:12 ){
    period = character()
    
    for (year in years ){
      for (month in seq_along(months)){
        this_period = paste0( ";", 
                         year , 
                         ifelse( month < 10 , paste0("0", month) , month )
        )
        period =  c(period, this_period )
      }
    }
    
    # remove first ;
    period =  paste( period, collapse = "")
    period = substring( period, 2, nchar(period))
    
    return( period )
  }
 
  periods = date_code() # default: 2013-2017
  # periods = date_code( 2017, 1 ) # January 2017 only
  
  # as character vector
  periods.vector = strsplit( periods, ";" , fixed = TRUE )[[1]]

  
```


```{r ou_levels}

    md$organisationUnitLevels %>% 
    select( id, name , level) %>% 
    arrange( level ) %>%
    kable

  # levels
      levels = character()
      for ( i in seq_along( md$organisationUnitLevels$id) ){
    
        levels =  c(levels, paste0("LEVEL-", i) )
      }
      
      levels = paste( levels, collapse = ";")
  
  # import month by month
  levels.vector = strsplit( levels, ";" , fixed = TRUE )[[1]]
  
```

## Data elements 

Data from selected data will be downloaded for the period 2013-2017, from all organizational units, as totals and details (with categoryOptionCombos).

```{r data_elements_include }

    # de.include = read_csv( de.review.filename  )

    de.include = readxl::read_xlsx( de.review.xlsx  ) %>% filter( !is.na(Include) )

    # divide elements into smaller parts
    
    # split elements into group of 50 
    section.size = 3
    de.names.sections = ceiling( length( de.include$Include ) / section.size )

    de.name.part = list()
    for ( section in 1:de.names.sections){
        start = (section-1)*section.size + 1
        if (section == 1 ) start = 1
        stop = (section)*section.size 
        if (stop > length(de.include$Include) ) stop = length(de.include$Include)
        
        de.name.part[[section]] = de.include$dataElement[ start:stop ] 
    }

```

## DataElements : Totals 

```{r fetch_data_values_total }

  data.totals.file = paste0( origin.folder , 
                     origin_login_file, 
                     "_dataset_totals.rds" )

    if ( file.exists( data.totals.file ) ){
        
          data_totals = readRDS( data.totals.file ) 
                                
          
    } else {
  
      # login in to server
      retry( login_origin() )
      
      # import month by month
      
      # initialize lists
      data = list()
      data.level = list()
      data.de = list()
      
      for ( i in seq_along(periods.vector) ){
    
          print( paste( periods.vector[i] ) )
        
        for ( level in seq_along( levels.vector ) ){
          
          print( levels.vector[level] )
            
            for ( de.section in 1:de.names.sections ){
                
                # data elements:
                de.ids = paste( 
                    md$dataElements$id[ md$dataElements$name %in% de.name.part[de.section][[1]] ],
                    collapse  = ";" )

                
                print( paste( periods.vector[i], levels.vector[level] , 
                              'part', de.section , "/" , de.names.sections) 
                       )
      
                #Assemble the URL ( before starting, double check semicolons for dx dimension )
                url <- paste0( baseurl, "api/analytics/dataValueSet.json?" ,
                      "&dimension=ou:", levels.vector[level] , 
                      "&dimension=pe:" , periods.vector[i] ,
                      "&dimension=dx:" , 

                      # malaria
                      de.ids ,
                      # opd summary
                      # "KNrK5VWTZkx;NLKRV7bYbVy" , # population
                      "&displayProperty=NAME")
      
                # Fetch data
                fetch <- retry( get(url)[[1]] ) # if time-out or other error, will retry 
                
                # if returns a data frame of values (e.g. not 'server error'), then keep
                if ( is.data.frame( fetch ) ){ 
                    data.de[[de.section]] = fetch
                } else {
                    data.de[[de.section]] = data_frame( NA )
                }
            }
            
            data.level[[level]] = data.table::rbindlist( data.de, fill = TRUE )
        }
        
    # combine level data
    data[[i]] = data.table::rbindlist( data.level , fill = TRUE )
    
        print( paste( scales::comma( nrow( data[[i]] ) ) , "records"  ) )
    
    }
  
      # combine period data
      data_totals = data.table::rbindlist( data , fill = TRUE)
      
      print( paste( "TOTAL:", scales::comma( nrow( data ) ) , "records"  ) )
     
      # save data
      saveRDS( data_totals, data.totals.file )
    }
      
    data_totals_date = file.info(data.totals.file)$mtime

    glimpse( data_totals ) 

```

The totals data was downloaded on `r data_totals_date`

## DataElements : Details

```{r fetch_data_values_details }

  data.details.file = paste0( origin.folder , 
                     origin_login_file, 
                     "_dataset_details.rds" )

    if ( file.exists( data.details.file ) ){
        
          data_details = readRDS( data.details.file ) 
                                
          
    } else {

      # login in to server
      retry( login_origin() )
      
      
      # initialise lists
      data = list()
      data.level = list()
      data.de = list()
      
    # import month by month , level, and data element
      for ( i in seq_along( periods.vector) ){ 
    
          print( paste( periods.vector[i] ) )
        
        for ( level in seq_along( levels.vector ) ){
          
          print( levels.vector[level] )
            
            for ( de.section in 1:de.names.sections ){
                
              # data elements to get:
                de.index =  md$dataElements$name %in% de.name.part[de.section][[1]] 
    
                # data.frame of dataElement-id and categorycomb0-id
                de.catCombo = data_frame( 
                    dataElement = md$dataElements$id[ de.index ] ,
                    dataElement.name = md$dataElements$name[ de.index ] ,
                    categoryCombo = md$dataElements$categoryCombo$id[ de.index ] 
    )
    
                # CategoryOptions for each categoryCombo
                catOptCombos =  data_frame( 
                    categoryOptionCombo = md$categoryOptionCombos$id ,
                    categoryCombo = md$categoryOptionCombos$categoryCombo$id
                )
                
                de.catOptCombo = de.catCombo %>% 
                    inner_join( catOptCombos , by = "categoryCombo")
                
                # string to paste in to data request    
                de.ids = paste( paste0( de.catOptCombo$dataElement, "." , 
                                        de.catOptCombo$categoryOptionCombo) ,
                                collapse  = ";" )

                print( paste( periods.vector[i], levels.vector[level] , 
                              'part', de.section , "/" , de.names.sections) 
                       )
                
                
      
        #Assemble the URL ( before starting, double check semicolons for dx dimension )
        url <- paste0( baseurl, "api/analytics/dataValueSet.json?" ,
                      "&dimension=ou:", levels.vector[level] , 
                      "&dimension=pe:" , periods.vector[i] ,
                      "&dimension=dx:" , 

                      # malaria
                      de.ids ,
                      # opd summary
                      # "KNrK5VWTZkx;NLKRV7bYbVy" , # population
                      "&displayProperty=NAME")
      
                # Fetch data
                fetch <- retry( get(url)[[1]] ) # if time-out or other error, will retry 
                
                # if returns a data frame of values (e.g. not 'server error'), then keep
                if ( is.data.frame( fetch ) ){ 
                    data.de[[de.section]] = fetch
                    
                } else {
                    data.de[[ de.section ]] = data_frame( NA )
                }
            }
            
            data.level[[level]] = data.table::rbindlist( data.de, fill = TRUE )
            
            print( paste( scales::comma( nrow( data.level[[level]] ) ) , "level records"  ) )
        }
          
    # combine level data
    data[[i]] = data.table::rbindlist( data.level, fill = TRUE )
    
        print( paste( scales::comma( nrow( data[[i]] ) ) , "period records"  ) )
    
    }
  
      # combine period data
      data_details = data.table::rbindlist( data , fill = TRUE)
      
      print( paste( "TOTAL:", scales::comma( nrow( data_details ) ) , "total records"  ) )
    
      # save data file           
      saveRDS( data_details, data.details.file )
}
      
    glimpse( data_details ) 
    
    data_details_date = file.info(data.details.file)$mtime
    
```

The detailed data was downloaded on `r data_details_date`

## Verify:  Sum of data-details equals data-totals

The following table is sorted by the difference between sums for each variable.

```{r verify_details_total }

    sum_details = data_details %>%
        group_by( dataElement ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        group_by( dataElement ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, by = 'dataElement' ) %>%
        left_join( md$dataElements %>% select( id, name ) , 
                   by = c( 'dataElement' = 'id' ) 
                   ) %>%
        select( dataElement, name, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma )
    
```

Why are some totals > than sum of details/categories?

```{r}
# summarise and compare by period

    # choose data element to examine
    de = 'GOXEXTR0uST'

# Compare by month
    sum_details = data_details %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' ) 
               ) %>%
        select( period, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma )
    
# Compare by month, orgUnit
    sum_details = data_details %>%
        filter( dataElement %in% de )  %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    compare = left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' , 'orgUnit' ) 
               ) %>%
        left_join( md$organisationUnits %>% select( id, name ) ,
                   by = c( 'orgUnit' = 'id' ) ) %>%
        select( period, orgUnit, name, sum_details,  sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma ) 
    
    compare %>% filter( difference > 0 ) %>% View
    
    count( compare %>% filter( difference > 0 ), period ) %>% print( n = 100 )
    
    # look at details...
    data_details %>% 
        select(dataElement,period, orgUnit, categoryOptionCombo, value) %>%
        filter( dataElement %in% de, 
                period %in% '201506',
                orgUnit %in% (compare %>% filter( difference > 0 ) %>% .$orgUnit) ) %>%
        spread( categoryOptionCombo, value ) %>%
        left_join( compare ) %>%
        View
```


Summarise data values by dataElement_categoryOptionCombo

```{r summarise_data_variables }
   dd = data_details %>%
        inner_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name )  %>%
        inner_join( md$categoryOptionCombos %>% select( id , name ) ,
                    by = c( 'categoryOptionCombo' = 'id' ) ) %>%
        rename( cat.name = name )  %>%
        unite( element_combo , de.name, cat.name )

    # spread data so that each column is a variable
    df = dd %>% 
        # select( orgUnit, period,  element_combo, value ) %>%
        mutate( value = as.numeric( value )) %>%
        spread( element_combo, value  ) %>%
        select( -orgUnit, -period )
    
    do.call( data.frame , 
           list(
               Element = names( df ) ,
               mean = map_dbl(df, ~round( mean( .x , na.rm = TRUE ) ) ),
                sd = map_dbl(df, ~round( sd( .x , na.rm = TRUE) ) ) ,
                median = map_dbl(df, median, na.rm = TRUE) ,
                min = map_dbl(df, min, na.rm = TRUE) ,
                max = map_dbl(df, max, na.rm = TRUE) ,
                n = map_dbl(df, length) ,
                nmiss =  map_dbl(df, ~sum( is.na(.x) ) )
           )) %>%
        mutate_if( is.numeric , comma ) %>% 
        datatable( rownames = FALSE , options = list( pageLength = 15) )
```



## Data: data elements

NB:  the counts include all of the option combos.  TODO:  recalculate

```{r count_dataElements_in_data, comment="" }

  # List data elements by name
  data_details %>% 
    # names of data elements
    left_join( select(md$dataElements, id, name) ,
                      by = c("dataElement" = "id")
                      ) %>%
    select( -dataElement ) %>% 
    rename( dataElement = name ) %>%
    # summarise reports by dataElement
    group_by( dataElement) %>% 
    summarise( 
        Reported = n() ,
        orgUnits = n_distinct( orgUnit ) ,
        First =  as.yearmon( min( period ), "%Y%m") %>% format(., "%b-%Y"),
        Last = as.yearmon( max( period ), "%Y%m") %>% format(., "%b-%Y")
        ) %>% 
    arrange( -Reported ) %>%
    mutate( Reported = comma( Reported ), 
            orgUnits = comma( orgUnits ) 
            ) %>%
    datatable( rownames = FALSE, options= list( pageLength = 15, scrollY = TRUE ) )
```

## Data: data sets

```{r count_dataset_in_data, comment=""}

  # data frame of datasets and data elements
  dsde = map_df( 1:length(md$dataSets$dataSetElements), 
            ~map_df( md$dataSets$dataSetElements[[.x]], 
                     ~as.matrix(.x) ))

  # List data elements by name
  data_details %>% 
     # link datasets
    left_join( dsde , by = "dataElement" 
                      ) %>%
      
    left_join( md$dataSets %>% select( id, name ), 
               by = c("dataSet"="id")
               ) %>%
    select( -dataSet ) %>%
    rename( dataSet = name ) %>% 
    group_by( dataSet ) %>%
    summarise( 
        Reported =  n() ,
        orgUnits = n_distinct( orgUnit )  ,
        dataElements = n_distinct( dataElement ) ,
        First =  as.yearmon( min( period ), "%Y%m") %>% format(., "%b-%Y"),
        Last = as.yearmon( max( period ), "%Y%m") %>% format(., "%b-%Y")
        ) %>% 
    arrange( -Reported ) %>%
    mutate( Reported = comma( Reported ), 
            orgUnits = comma( orgUnits ) ,
            dataElements = comma( dataElements )
            ) %>%
    datatable( rownames = FALSE, options= list( pageLength = 15 , scrollY = TRUE) )
  
```

## Which are the most informative data elements?

- Completeness

- Continuity

## Trends

- Identify most important dataElements and dataSets (do this nationally, and by county)

1. Find HF that have been continuously reporting; compare the trend with rest of the data   
    a. sum case counts by month   
    b. Use seasonal decomposition models to estimate trends   
    
2. Calculate mean case count by month across all clinics (assumes that clinic case counts are normally distributed)
    
3. Calculate incidence with available population data--if it is by health facility

4. Calculate case rate per 1,000 patients attending each HF, then take mean of across all HF

5. Impute missing values based on location, # patients
