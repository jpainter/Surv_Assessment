---
output:
  html_document:
    
    # css: custom.css
    toc: true
    toc_float: true
    code_folding: hide
    fig_caption: yes
    self_contained: no
  word_document: 
    toc: true
    fig_caption: yes
    
always_allow_html: yes
editor_options: 
  chunk_output_type: console
params:
  data_directory: 
  dhis_instance: Uganda
  create_new: FALSE 
  dataset_directory:  datasets  
  output_directory: ./ # bug: only uses current directory
  cache: FALSE
  echo: FALSE
---

```{r run_this_code_to_create_and_save_a_copy, eval= FALSE}
 # pander...rmarkdown....
```


# **`r params$dhis_instance`** {.tabset .tabset-fade}
<!-- load libraries... -->

```{r packages, message=FALSE, include= FALSE, warning= FALSE }

# # list of required packages
#     package.list = c( "openxlsx", "readxl" , "rlist", "knitr", "kableExtra", "xts", "leaflet", "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "scales", "RcppRoll", "zoo", "gridExtra", "futile.logger", "zoo" , "broom" , "Hmisc", "plotly" , "skimr", "knitrProgressBar" , "tidyverse"  )

# list of required packages
    package.list = c("rlist", "listviewer", "DT", "knitr", "kableExtra", "xts", "leaflet", "geojsonR", "rmapshaper" , "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "scales", "RcppRoll", "zoo", "gridExtra", "futile.logger", "Hmisc", "skimr" , "stringi", "rlang" , "tidyselect" , "readxl", "knitrProgressBar" , "tidyverse" )

# Function to test if package is installed 
    pkgTest <- function( package.list = package.list ){
        
        missing.packages = setdiff( package.list , rownames(installed.packages())) 
        if ( length( missing.packages ) > 0 ) install.packages( missing.packages ) 
    }


# Test if packages loaded
    pkgTest( package.list )

# load the packages
    lapply( package.list, suppressMessages( require ) , character.only = TRUE)


knitr::opts_chunk$set( echo = params$echo ,
                       message = FALSE ,
                       comment = "" ,
                       fig.width =  8,
                       fig.height = 10 ,
                       dpi = 300 ,
                       out.width = "100%" ,
                       out.height = "75%" ,
                       # knitr.table.format = "html" ,
                       cache = params$cache # TRUE for testing; FALSE for production
                       )

```

<!-- ...functions for fetching metadata -->

```{r sources, include= FALSE }

source('dhis2_functions.R')

    
    data_directory = params$data_directory
    dhis_instance = params$dhis_instance
    output_directory = getwd() # params$output_directory
  
  # folder for storing review data

  origin.folder = paste0( ifelse( is.na( data_directory ), "" , 
                                  paste0( data_directory, "/" ) 
                                  ) ,
                          dhis_instance , "/")
  
   # sub-folder for data
   dataset.directory = paste0( origin.folder , params$dataset_directory , "/" )
    
 # login shortcuts

  # origin.login shortcut
   origin.login = function(){
       source( paste0( origin.folder , 
                       tolower( dhis_instance ) , 
                       "_login")  )
       # print( baseurl )
       loginDHIS2( baseurl, username, password)
   }
  
```


```{r all_meta }

  meta_data_file = paste0( dataset.directory , 
                           dhis_instance, 
                           "_metadata.rds" )

  md = read_rds( meta_data_file )

  # re-order alaphabetically to be easier to browse in View
  md = md[order(names(md))]
  
  # Retrieve access data 
  date_metadata = file.info( meta_data_file )$ctime 
  
```

Data from selected data will be downloaded for the period 2013-2017, from all organizational units, as totals and details (with categoryOptionCombos).



```{r date_strings }

 
  periods = date_code() # default: 2013-2017
  # periods = date_code( 2017, 1 ) # January 2017 only
  
  # as character vector
  periods.vector = strsplit( periods, ";" , fixed = TRUE )[[1]]

  
```

```{r ous }  

# Same code as chunk 'ou_and_levels' from Metadata_Review.Rmd

feature_type = function( coordinate ){
    n = length( gregexpr( '[' , coordinate , fixed = TRUE)[[1]] )
    
    if ( is.na( coordinate ) ) return(NA)
    if (n==1) return('Point') 
    if (n>1) return('Polygon') 
    

}



  parse_parent_ous = function( path ){
       breaks = gregexpr("/", path , perl = TRUE)[[1]]
       n = length( breaks ) 
       if ( n == 0 ) return( NA ) 
       if ( n == 1 ) return( substr( path , breaks[1] + 1 , length(path) ) ) 
       substr( path , breaks[n-1] + 1 , breaks[n]-1 )
  }
  
   ous =  md$organisationUnits %>% 
        select( id, path, name, shortName, coordinates , 
                created, lastUpdated, ends_with('Date') 
                ) %>% as_tibble %>%
       rename( ous = name ) %>%
        mutate( 
          ous = ifelse( ous %in% "", shortName, ous ) , #if name blank, use shortName
          level = map_chr( path, 
                               ~length( gregexpr("/", .x, perl = TRUE)[[1]]) 
                               ) ,
          parent.id =  map_chr( path, ~parse_parent_ous( .x ) ) ,
          feature = map_chr( coordinates, ~feature_type(.x ) )
        ) %>%
       # Name of parent
       left_join( md$organisationUnits %>% select( id, name ) ,
                   by = c('parent.id' = 'id' ) ) %>%
       rename( parent = name ) %>%
       # Name of level
       left_join( md$organisationUnitLevels %>% select( level, name ) %>%
                      mutate( level = as.character( level ) ),
                  by = 'level' ) %>%
       rename( level.name = name)
    
```

```{r ou_levels }
# levels
      levels = character()
      for ( i in seq_along( md$organisationUnitLevels$id) ){
    
        levels =  c(levels, paste0("LEVEL-", i) )
      }
      
      levels = paste( levels, collapse = ";")
  
  # import month by month
  levels.vector = strsplit( levels, ";" , fixed = TRUE )[[1]]
  
```


# Data elements {.tabset .tabset-fade}


```{r data_elements_include }


   de.include.xlsx = paste0( dataset.directory , 
                             dhis_instance , 
                             "_dataElements_selected.xlsx" )
 
# if file exists, rename
  if ( file.exists( de.include.xlsx )   ){ 
        
        de.include = readxl::read_xlsx( de.include.xlsx ) 
            
    }

```


## DataElements : Details

<!-- TODO: Look at data_totals and decide if details needed -->

```{r data_details}
## DataElements : details 

    data.details.file = paste0( dataset.directory ,  
                     dhis_instance, 
                     "_details.rds" )

    if ( file.exists( data.details.file )  ){
        
        data_details = read_rds( data.details.file )
    }

    print( paste( "TOTAL:", 
                  scales::comma( nrow( data_details ) ) , 
                  "records"  ) )

    # get date
    data_details_date = file.info( data.details.file )$mtime
        

```


The detailed data was downloaded on `r data_details_date`

Summarise data details values by dataElement_categoryOptionCombo 

```{r summarise_data_variables }
   dd = data_details %>%
        inner_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name )  %>%
        inner_join( md$categoryOptionCombos %>% select( id , name ) ,
                    by = c( 'categoryOptionCombo' = 'id' ) ) %>%
        rename( cat.name = name )  %>%
        unite( element_combo , de.name, cat.name )

    # spread data so that each column is a variable; keep only numeric cols
    ## !! Memeory error with large datasets (e.g. Uganda but not malawi)
    # df = dd %>% 
    #     group_by( level ) %>%
    #     # select( orgUnit, period,  element_combo, value ) %>%
    #     mutate( value = as.integer( value )) %>%
    #     spread( element_combo, value  ) %>%
    #     purrr::keep(is.integer)
    
    # Try same wtih data.table
    dd = data.table::data.table( dd %>%
        mutate( value = as.integer( value ))
        )
    
    df = data.table::dcast( dd , level + orgUnit + period ~ element_combo, 
                value.var = "value") 
        
    
    skim_format(numeric = list(digits = 2,  big.mark = ","))
    skim_to_wide( df ) %>% pander( split.table = Inf  )
    
    ## html data table
    # stw = skim_to_wide( df %>% filter( level == 4 ) ) 
    # datatable( stw )
    
    # # glimpse(df) 
    # 
    # do.call( data.frame , 
    #        list(Element = names(df ) ,
    #             mean = map_dbl( df , ~round( mean( .x , na.rm = TRUE ) ) ) ,
    #             sd = map_dbl(df , ~round( sd( .x , na.rm = TRUE) ) ) ,
    #             median = map_dbl(df  , median, na.rm = TRUE) ,
    #             min = map_dbl(df , min, na.rm = TRUE) ,
    #             max = map_dbl(df  , max, na.rm = TRUE) ,
    #             n = map_dbl(df  , length) ,
    #             nmiss =  map_dbl(df , ~sum( is.na(.x) ) )
    #        )) %>%
    #     mutate_if( is.numeric , comma ) %>% 
    #     datatable( rownames = FALSE , options = list( pageLength = 15) )
    # 
    # 
```


## DataElements : Totals 

```{r data_totals}
 data_totals  = data_details %>% 
    group_by( period, orgUnit, dataElement ) %>%
    summarise( value = sum( as.integer( value ) )) %>%
    ungroup()
```


## DataSet - DataElement List 

```{r dsde }

  # data frame of datasets (ds) and data elements (de)
  dsde = map_df( 1:length(md$dataSets$dataSetElements), 
            ~map_df( md$dataSets$dataSetElements[[.x]], 
                     ~as.matrix(.x) ))

# For versions <2.6, need to add categoryCombo
    if ( !'categoryCombo' %in% names(dsde) ){
      categoryCombos =  data_frame(
          dataSet = md$dataSets$id ,
          categoryCombo = md$dataSets$categoryCombo$id )
      
      dsde = dsde %>% inner_join( categoryCombos,  by = "dataSet")
    }


    # Data elements in data.totals
    de = data_totals %>% select( dataElement ) %>% distinct 
    
    # display with names
    datasetsWithDE = dsde %>%
        left_join( md$dataSets %>% select( id, name ), 
                   by = c("dataSet"="id")
                   ) %>%
        select( -dataSet ) %>%
        rename( dataSet = name ) %>% 
        left_join( md$dataElements %>% select( id, name ), 
                   by = c("dataElement"="id")
                   ) %>%
        select( -dataElement ) %>%
        rename( dataElement = name ) %>% 
        left_join( md$categoryCombos %>% select( id, name ), 
                   by = c("categoryCombo"="id")
                   ) %>%
        select( -categoryCombo ) %>%
        rename( categoryCombo = name ) 
        
        datatable( datasetsWithDE , rownames = FALSE,
                   options= list( pageLength = 15 ,
                                  scrollY = TRUE)
                   ) 

  
```


# Data Completeness {.tabset .tabset-fade}

Values shown are for the periods from `r min(periods.vector)` to `r max(periods.vector)`.


```{r download_dataset_submissions }
## DataElements : details 

  dataset.reporting.file = paste0( dataset.directory ,  
                     dhis_instance ,  
                     "_dataset_reporting.rds" )

    if ( file.exists( dataset.reporting.file )  ){
        
        data_submissions = readRDS( dataset.reporting.file ) 
        
    }         

    # get date
    data_submissions_date = file.info( dataset.reporting.file )$mtime

```


## Dataset 'Completeness' (form submission rate) 

- Dataset 'completeness', better described as form submission rate because it indicates the number of facilties that submitted a report, regardless of th completeness of the report.   

<!-- What would be really cool--to show number of orgunits available, assigned to dataset, and actually submitted data for each dataset/data element. -->

```{r dataset_completeness }
  
  d_submissions =  data_submissions %>% 
        separate( col = dataElement , 
                  into = c('dataSet', 'Category' ), 
                  sep = "\\.") %>%
        select( dataSet , Category, period, orgUnit, value ) %>%
        mutate( value = as.integer( value ) ) %>%
        spread( Category , value ) %>%
        mutate( reporting_ratio = ACTUAL_REPORTS / EXPECTED_REPORTS ) %>%
        inner_join( md$dataSets %>% select( id, name ) , 
                    by = c( 'dataSet' = 'id') ) %>% 
        rename( dataSet = name , dataSet.id = dataSet) %>% 
        inner_join( ous %>% select( ous, parent, level, level.name , feature, id ), 
                    by = c( 'orgUnit' = 'id' ) 
                        ) 
    
                     
  # s = d.ous  %>%
  #   # mutate( 
  #   #     ous = fct_reorder( ous, level )
  #   #     ) %>%
  #   group_by( period, level, level.name , dataSet , Category ) %>%
  #   summarise( report = n() )  %>% 
  #   left_join( count( ous, level ) , by = 'level' ) %>%
  #   mutate( completeness = report / n ) %>%
  #   ungroup()
  
  # convert month-Yr to date
  d_submissions$date = fast_strptime( as.character(  d_submissions$period ) ,
                                      "%Y%m") %>% as.POSIXct()
  
```

This chart shows the percentage of active organisational units that were expected to report during each period.  Any value less than 100% indicates that some organisational units were not assigned the dataset report.  

```{r expected_reports}
  # summary( s$completeness )
  
    ggplot( d_submissions ,
           aes(x = date, y = reporting_ratio , 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_wrap( ~ dataSet, 
                labeller = label_wrap_gen( width = 25, multi_line = TRUE) ,
                ncol = 4 ,
                scales = 'free'
                ) +
    labs( title = 'Percent of OrgUnits Expected to Report', 
             # subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance ,
          x = "Percent"
             ) +
    scale_y_continuous(labels = scales::percent)
  
```


This chart shows the perecentage of active organisational units that reported, and reported on time, during each period.  Completeness is shown by level, because a report was submitted at upper levels does not indicate the percentage of reports submitted by the lower levels organisation units. **Attention should be given to the lowest level, e.g. health facilities, where data is reported.** 

```{r actual_reports}
  # summary( s$completeness )
  

    ggplot( d_submissions ,
           aes(x = date, y = ACTUAL_REPORTS , 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_wrap( ~ dataSet, 
                labeller = label_wrap_gen( width = 25, multi_line = TRUE) ,
                ncol = 4,
                scales = 'free'
                ) +
        
    labs( title = 'Actual Number of Reports Submitted', 
             # subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance
             ) 
    

    
```

```{r actual_onTime_reports}
  # summary( s$completeness )
  
  
    ggplot(d_submissions ,
           aes(x = date, y = ACTUAL_REPORTS_ON_TIME / EXPECTED_REPORTS , 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_wrap( ~ dataSet, 
                labeller = label_wrap_gen( width = 25, multi_line = TRUE) ,
                ncol = 4, 
                scales =  'free'
                ) +
        
    labs( title = 'Percentage of Expected Recports Submitted On-Time', 
             # subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance
             ) +
        
    scale_y_continuous(labels = scales::percent)
    

```

## Percent completeness by Data Element

- crude measure with denom = all orgunits

```{r Submission_de_details }


    data.details.count.file = paste0( dataset.directory , 
                               dhis_instance,
                               "_count_details.rds" )

    data.details.count = read_rds( data.details.count.file ) 
    
    #  glimpse( data.details.count )
    
    
    # List of datasets associated with dataElements
    dsde = dataSet_dataElement_df( md )
    # View( dsde )
    
    ## filter to those datasets with dataElements in data.details.count
    dsde = dsde %>% 
      filter( dataElement.id %in% unique( data.details.count$dataElement )) %>%
      select( dataSet , dataElement , dataElement.id ) %>%
      group_by( dataElement.id, dataElement ) %>%
      summarise( dataSet = paste( dataSet , collapse = " ;\n ") )
    
    ## get names for dataElement, catefogies, etc, 
    ## link with datasets
    d.details.count = data.details.count %>% 
      filter( level %in% 1 , !is.na(orgUnit ) ) %>%
      select( level, orgUnit, dataElement, categoryOptionCombo,  
              period, value ) %>%
      dhis2_Join_metadata( 'dataElements', 'dataElement') %>%
      dhis2_Join_metadata( 'categoryOptionCombos', 'categoryOptionCombo') %>%
      # dhis2_Join_metadata( 'organisationUnits', 'orgUnit') %>%
      inner_join( dsde %>% select( dataSet , dataElement.id ), 
                  by = c("dataElement" = "dataElement.id")
                  ) %>%
      mutate( value = as.integer( value ))

    # View(d.details.count)

    # s = data_details %>% select( -level ) %>%
    #     left_join(  ous %>% select( id, level, level.name ) , 
    #                 by = c('orgUnit' = 'id') ) %>%
    #     count( dataElement , categoryOptionCombo, level, level.name , period ) %>% 
    #     rename( reported = n ) %>%
    #     left_join( count( ous, level ) , by = 'level' ) %>%
    #     rename( expected = n ) %>%
    #     mutate( 
    #         completeness = reported / expected 
    #         ) %>%
    # 
    #     # data element names 
    #     rename( id = dataElement ) %>%
    #     left_join( 
    #         md$dataElements %>% select( id, name ) , 
    #         by = c( 'id' ) 
    #         ) %>%
    #     rename( dataElement = name )

    # convert month-Yr to date
    d.details.count$date = fast_strptime( 
      as.character(  d.details.count$period ) , "%Y%m"
      ) %>% 
      as.POSIXct()
  
    # summary( s$completeness )
  

```



```{r de_completeness_charts}

dataSets = unique( d.details.count$dataSet)

expected_submissions = d_submissions %>% 
  filter( map_lgl( dataSet, ~grepl( .x, dataSets[1] )), date %in% max( date, na.rm = T )) %>%
  pull ( EXPECTED_REPORTS ) %>% max

# percent completeness 
    ggplot(d.details.count %>% filter( dataSet %in% dataSets[1]),  
           aes(x = date, y = value / expected_submissions , 
                   group = categoryOptionCombo.name , 
               color = categoryOptionCombo.name )
           ) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_grid( dataSet ~ dataElement.name , 
                labeller = label_wrap_gen(width = 25, multi_line = TRUE) 
                ) +
    labs( title = 'Percent completeness by level', 
             subtitle =  'Relative to most recent number of reports expected' ,
             caption = params$origin_login_file
             ) +
    theme_minimal() +
    scale_y_continuous(labels = scales::percent, breaks = seq(0,1,.1))
    
    # ggplotly( g )
    
```

## Actual Number Reports by Data Element

```{r , out.height="150%"}
# Actual number
    ggplot(s %>% filter(expected >=20 ),  aes(x = date, y = reported, 
                   group = level.name , color = level.name )) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_wrap( ~ dataElement,
                labeller = label_wrap_gen(width = 25, multi_line = TRUE) ,
                ncol = 4
                ) +
    labs( title = 'Actual reports by level', 
             subtitle =  '' ,
             caption = params$origin_login_file
             ) +
    theme( strip.text = element_text( size = 6 ) )
```

## Reported dataElement by dataSet, level

Table of number of org units that provided data for each data element, stratified by dataset (row headings) and orgUnit level (column headings).  

```{r Submission_de_Totals }

 d = data_totals  %>% 
     
     # select( -level ) %>%
    
    # Remove any rows with all missing data
    filter( complete.cases(.) ) %>%
    
    # get ou level 
    left_join(
        select( ous , id, level ) , 
        by = c('orgUnit' = 'id')
    ) %>% 
    
    # join dataset to dataElement
    left_join( dsde, by = 'dataElement' ) %>%
    
    # Summarize by element and level--all dates
    group_by( dataSet, dataElement , level ) %>%
    summarise( n = n_distinct( orgUnit ) )   %>%
    ungroup %>%
     
    #dataset name
    rename( id = dataSet ) %>%
    left_join( md$dataSets %>% select( id, name ) ,  by = 'id'  ) %>%
    rename( dataSet = name ) %>%
    select( -id ) %>%
     
    # data element name
    rename( id  = dataElement ) %>%
    left_join( md$dataElements %>% select( id, name ) , by = 'id' ) %>%
    rename( dataElement = name ) %>%
    select( -id ) %>%
     
    spread( level, n ) 
 
 # kable( d, 'html' ) %>% 
 #       kable_styling(bootstrap_options = c("striped", "hover") ) %>%
 #        column_spec(1, bold = T) 
 
 d  %>%
 pander( split.table = Inf , big.mark = "," )
 
```

- Summarise org units open each period

Limitation: Because only one openiningDate is recorded, if clinic was closed, then reoppened, it will be reported as if it was always open.  


<!-- NB:  Use API to save charts as favorites??? -->

<!-- Compare with indicators from other programs--tb, hiv, imm... -->

# Anomalies

This section will be to identify extreme values that are most likely data entry errors.  Some decisions will need to be made about whether to remove or replace those values for the rest of the anlyses. 

Detect outliers/anomalies:  
- WHO Outilier detection
- Anomallize

# Population and Attendance 

# Field visits

- site selection options
