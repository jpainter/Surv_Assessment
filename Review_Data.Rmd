---
output:
  html_document:
    # css: custom.css
    toc: true
    toc_float: true
    code_folding: hide
    fig_caption: yes
    self_contained: no
editor_options: 
  chunk_output_type: console
params:
  dhis_instance: Malawi
  create_new: FALSE 
  data_directory:  
  output_directory: ./ # bug: only uses current directory
  cache: FALSE
  echo: FALSE
---

# **`r params$dhis_instance`** {.tabset .tabset-fade}
<!-- load libraries... -->

```{r packages, message=FALSE, include= FALSE, warning= FALSE }

# # list of required packages
#     package.list = c( "openxlsx", "readxl" , "rlist", "knitr", "kableExtra", "xts", "leaflet", "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "scales", "RcppRoll", "zoo", "gridExtra", "futile.logger", "zoo" , "broom" , "Hmisc", "plotly" , "skimr", "knitrProgressBar" , "tidyverse"  )

# list of required packages
    package.list = c("rlist", "listviewer", "DT", "knitr", "kableExtra", "xts", "leaflet", "geojsonR", "rmapshaper" , "RColorBrewer", "DT", "dygraphs", "httr", "jsonlite", "XML", "assertthat", "lubridate", "scales", "RcppRoll", "zoo", "gridExtra", "futile.logger", "Hmisc", "skimr" , "stringi", "rlang" , "tidyselect" , "readxl", "knitrProgressBar" , "tidyverse" )

# Function to test if package is installed 
    pkgTest <- function( package.list = package.list ){
        
        missing.packages = setdiff( package.list , rownames(installed.packages())) 
        if ( length( missing.packages ) > 0 ) install.packages( missing.packages ) 
    }


# Test if packages loaded
    pkgTest( package.list )

# load the packages
    lapply( package.list, suppressMessages( require ) , character.only = TRUE)


knitr::opts_chunk$set( echo = params$echo ,
                       message = FALSE ,
                       comment = "" ,
                       fig.width =  8,
                       out.width = "100%" ,
                       out.height = "75%" ,
                       # knitr.table.format = "html" ,
                       cache = params$cache # TRUE for testing; FALSE for production
                       )

```

<!-- ...functions for fetching metadata -->

```{r sources, include= FALSE }

source('dhis2_functions.R')

    
    data_directory = params$data_directory
    dhis_instance = params$dhis_instance
    output_directory = getwd() # params$output_directory
  
  # folder for storing review data

  origin.folder = paste0( ifelse( is.na( data_directory ), "" , 
                                  paste0( data_directory, "/" ) 
                                  ) ,
                          dhis_instance , "/")
  
 # login shortcuts

  # origin.login shortcut
   origin.login = function(){
       source( paste0( origin.folder , 
                       tolower( dhis_instance ) , 
                       "_login")  )
       # print( baseurl )
       loginDHIS2( baseurl, username, password)
   }
  
```


```{r all_meta }

  meta_data_file = paste0( origin.folder ,
                           dhis_instance, 
                           "_metadata.rds" )

  md = read_rds( meta_data_file )

  # re-order alaphabetically to be easier to browse in View
  md = md[order(names(md))]
  
  # Retrieve access data 
  date_metadata = file.info( meta_data_file )$ctime 
  
```

Data from selected data will be downloaded for the period 2013-2017, from all organizational units, as totals and details (with categoryOptionCombos).



```{r date_strings }

 
  periods = date_code() # default: 2013-2017
  # periods = date_code( 2017, 1 ) # January 2017 only
  
  # as character vector
  periods.vector = strsplit( periods, ";" , fixed = TRUE )[[1]]

  
```

```{r ous }  

# Same code as chunk 'ou_and_levels' from Metadata_Review.Rmd

feature_type = function( coordinate ){
    n = length( gregexpr( '[' , coordinate , fixed = TRUE)[[1]] )
    
    if ( is.na( coordinate ) ) return(NA)
    if (n==1) return('Point') 
    if (n>1) return('Polygon') 
    

}

  # levels
  levels = character()
    
  for ( i in seq_along( md$organisationUnitLevels$id) ){
    
        levels =  c(levels, paste0("LEVEL-", i) )
      }
      
  levels = paste( levels, collapse = ";")
  
  levels.vector = strsplit( levels, ";" , fixed = TRUE )[[1]]


  parse_parent_ous = function( path ){
       breaks = gregexpr("/", path , perl = TRUE)[[1]]
       n = length( breaks ) 
       if ( n == 0 ) return( NA ) 
       if ( n == 1 ) return( substr( path , breaks[1] + 1 , length(path) ) ) 
       substr( path , breaks[n-1] + 1 , breaks[n]-1 )
  }
  
   ous =  md$organisationUnits %>% 
        select( id, path, name, shortName, coordinates , 
                created, lastUpdated, ends_with('Date') 
                ) %>% as.tibble %>%
       rename( ous = name ) %>%
        mutate( 
          ous = ifelse( ous %in% "", shortName, ous ) , #if name blank, use shortName
          level = map_chr( path, 
                               ~length( gregexpr("/", .x, perl = TRUE)[[1]]) 
                               ) ,
          parent.id =  map_chr( path, ~parse_parent_ous( .x ) ) ,
          feature = map_chr( coordinates, ~feature_type(.x ) )
        ) %>%
       # Name of parent
       left_join( md$organisationUnits %>% select( id, name ) ,
                   by = c('parent.id' = 'id' ) ) %>%
       rename( parent = name ) %>%
       # Name of level
       left_join( md$organisationUnitLevels %>% select( level, name ) %>%
                      mutate( level = as.character( level ) ),
                  by = 'level' ) %>%
       rename( level.name = name)
    
```

```{r ou_levels}
# levels
      levels = character()
      for ( i in seq_along( md$organisationUnitLevels$id) ){
    
        levels =  c(levels, paste0("LEVEL-", i) )
      }
      
      levels = paste( levels, collapse = ";")
  
  # import month by month
  levels.vector = strsplit( levels, ";" , fixed = TRUE )[[1]]
  
```


# Data elements {.tabset .tabset-fade}


```{r data_elements_include }


    de.review.xlsx = paste0( output_directory , "/" ,
                             dhis_instance , "/" ,
                             dhis_instance , "_" , 
                             "dataElements.xlsx" ) 

    sheets = excel_sheets(de.review.xlsx) 
    
    use_these_sheets = sheets %in% c( "malaria_stock", "stock", "pop", "attendance", "opd" ,
                                      "ipd" , "malaria_items")
    
    target_sheets = sheets[ use_these_sheets ]  
    
    # get selected rows from every spreadsheet tab
    de.include = map_df(  seq_along( target_sheets ) , 
                         ~readxl::read_xlsx( de.review.xlsx ,  sheet = target_sheets[.x] ) %>% 
                             filter( !is.na(Include) ) ) %>%
        
        distinct( dataElement.id, .keep_all = TRUE )

    # if none selected, pick intersection of malaria and confirmed 
    if ( nrow( de.include) == 0 ){
        
        de.include = read_rds( paste0( origin.folder ,
                               dhis_instance, 
                               "_key_data_elements.rds" ) 
                            ) 
            
    }

```


## DataElements : Totals 

```{r data_total }
  
    data.totals.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_totals.rds" )

    nde = length( de.include )

    if ( nde > 0 & params$create_new | !file.exists( data.totals.file ) ){
    
        data_totals = api_data( 
            
            levels = levels.vector , 
            de.vars = de.include ,
            file = data.totals.file ,
            details = FALSE , 
            submissions =  FALSE )
        
        print( paste( "TOTAL:", 
                       scales::comma( nrow( data_totals ) ) , 
                       "records"  ) )
    
    } else {
        
        data_totals = readRDS( data.totals.file )
    }
    
    if ( file.exists( data.totals.file ) & params$create_new ){
        
        file.rename( data.totals.file ,
                     paste( data.totals.file ,
                            format( Sys.time(), "%b%d%Y" )
                            )
                     )
    }
    
    if ( !file.exists( data.totals.file) ) saveRDS( data_totals , data.totals.file )
        
    # get date
    data_totals_date = file.info( data.totals.file )$mtime
        

```


The totals data, `r scales::comma( nrow( data_totals ) )` records,  was downloaded on `r data_totals_date`.


```{r count_dataElements_in_data, comment="" }

  # List data elements by name
  data_totals %>% 
    # names of data elements
    left_join( select(md$dataElements, id, name) ,
                      by = c("dataElement" = "id")
                      ) %>%
    select( -dataElement ) %>% 
    rename( dataElement = name ) %>%
    # summarise reports by dataElement
    group_by( dataElement) %>% 
    summarise( 
        Reported = n() ,
        orgUnits = n_distinct( orgUnit ) ,
        First =  as.yearmon( min( period ), "%Y%m") %>% format(., "%b-%Y"),
        Last = as.yearmon( max( period ), "%Y%m") %>% format(., "%b-%Y")
        ) %>% 
    arrange( -Reported ) %>%
    mutate( Reported = comma( Reported ), 
            orgUnits = comma( orgUnits ) 
            ) %>%

    datatable( rownames = FALSE, options= list( pageLength = 15, scrollY = TRUE ) )


```

## Describe data elements


```{r describe_totals}

   dt = data_totals %>%
        left_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name ) 

    # spread data so that each column is a variable; keep only numeric cols
    df = dt %>% 
        # select( orgUnit, period,  element_combo, value ) %>%
        mutate( value = as.numeric( value ), 
                year = substr(period, 1,4) ) %>%
        select( period, year , orgUnit, value, de.name ) %>%
        spread( de.name, value  ) 
    
    
    skim( df )
 
```


## DataElements : Details

<!-- TODO: Look at data_totals and decide if details needed -->

```{r data_details}
## DataElements : details 

    data.details.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_dataset_details.rds" )

    nde = length( de.include )

    if ( nde > 0 & params$create_new | !file.exists( data.details.file )  ){
            
        data_details = api_data( 
            
            periods = periods.vector , 
            levels = levels.vector , 
            de.vars = de.include ,
            file = data.details.file ,
            details = TRUE , 
            submissions =  FALSE 
            
            )
        
        print( paste( "TOTAL:", 
                  scales::comma( nrow( data_details ) ) , 
                  "records"  ) )
    
    }
    
    if ( file.exists( data.details.file ) & params$create_new ){
        
        file.rename( data.details.file ,
                     paste( data.details.file ,
                            format( Sys.time(), "%b%d%Y" )
                            )
                     )
    }
    
    if ( !file.exists( data.details.file) ) saveRDS( data_details , data.details.file )
    
    
    data_details = readRDS( data.details.file )   
    
    
    # get date
    data_details_date = file.info( data.details.file )$mtime
        

```


The detailed data was downloaded on `r data_details_date`

Summarise data details values by dataElement_categoryOptionCombo 

```{r summarise_data_variables }
   dd = data_details %>%
        inner_join( md$dataElements %>% select( id , name ) ,
                    by = c( 'dataElement' = 'id' ) ) %>%
        rename( de.name = name )  %>%
        inner_join( md$categoryOptionCombos %>% select( id , name ) ,
                    by = c( 'categoryOptionCombo' = 'id' ) ) %>%
        rename( cat.name = name )  %>%
        unite( element_combo , de.name, cat.name )

    # spread data so that each column is a variable; keep only numeric cols
    df = dd %>% 
        group_by( level ) %>%
        # select( orgUnit, period,  element_combo, value ) %>%
        mutate( value = as.numeric( value )) %>%
        spread( element_combo, value  ) %>%
        purrr::keep(is.numeric)
    
    skim( df )
    
    stw = skim_to_wide( df %>% filter( level == 4 ) ) 
    datatable( stw )
    
    # # glimpse(df) 
    # 
    # do.call( data.frame , 
    #        list(Element = names(df ) ,
    #             mean = map_dbl( df , ~round( mean( .x , na.rm = TRUE ) ) ) ,
    #             sd = map_dbl(df , ~round( sd( .x , na.rm = TRUE) ) ) ,
    #             median = map_dbl(df  , median, na.rm = TRUE) ,
    #             min = map_dbl(df , min, na.rm = TRUE) ,
    #             max = map_dbl(df  , max, na.rm = TRUE) ,
    #             n = map_dbl(df  , length) ,
    #             nmiss =  map_dbl(df , ~sum( is.na(.x) ) )
    #        )) %>%
    #     mutate_if( is.numeric , comma ) %>% 
    #     datatable( rownames = FALSE , options = list( pageLength = 15) )
    # 
    # 
```



## Verify:  Sum of data-details equals data-totals

The following table is sorted by the difference between sums for each variable.

```{r verify_details_total }

    sum_details = data_details %>%
        group_by( dataElement ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        group_by( dataElement ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, by = 'dataElement' ) %>%
        left_join( md$dataElements %>% select( id, name ) , 
                   by = c( 'dataElement' = 'id' ) 
                   ) %>%
        select( dataElement, name, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma ) %>%
        datatable()
    
```

Why are some totals > than sum of details/categories? (only evaluate if there is problem verify that sum(details) = totals)

```{r, eval = FALSE}

# summarise and compare by period

    # choose data element to examine
    de = 'GOXEXTR0uST'

# Compare by month
    sum_details = data_details %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' ) 
               ) %>%
        select( period, sum_details, sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma )
    
# Compare by month, orgUnit
    sum_details = data_details %>%
        filter( dataElement %in% de )  %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_details = sum( as.numeric( value ) , na.rm = TRUE ) 
        )

    sum_totals = data_totals %>%
        filter( dataElement %in% de ) %>%
        group_by( dataElement , period, orgUnit ) %>%
        summarise(
            sum_totals = sum( as.numeric( value ) , na.rm = TRUE ) 
        )
    
    compare = left_join( sum_details , sum_totals, 
               by = c( 'dataElement', 'period' , 'orgUnit' ) 
               ) %>%
        left_join( md$organisationUnits %>% select( id, name ) ,
                   by = c( 'orgUnit' = 'id' ) ) %>%
        select( period, orgUnit, name, sum_details,  sum_totals ) %>% 
        mutate( difference = abs( sum_totals - sum_details ) )  %>%
        arrange( -difference ) %>%
        mutate_if( is.numeric, comma ) 
    
    compare %>% filter( difference > 0 ) %>% View
    
    count( compare %>% filter( difference > 0 ), period ) %>% print( n = 100 )
    
    # look at details...
    data_details %>% 
        select(dataElement,period, orgUnit, categoryOptionCombo, value) %>%
        filter( dataElement %in% de, 
                period %in% '201506',
                orgUnit %in% (compare %>% filter( difference > 0 ) %>% .$orgUnit) ) %>%
        spread( categoryOptionCombo, value ) %>%
        left_join( compare ) %>%
        View
```


## DataSet - DataElement List 

```{r dsde }

  # data frame of datasets (ds) and data elements (de)
  dsde = map_df( 1:length(md$dataSets$dataSetElements), 
            ~map_df( md$dataSets$dataSetElements[[.x]], 
                     ~as.matrix(.x) ))

# For versions <2.6, need to add categoryCombo
    if ( !'categoryCombo' %in% names(dsde) ){
      categoryCombos =  data_frame(
          dataSet = md$dataSets$id ,
          categoryCombo = md$dataSets$categoryCombo$id )
      
      dsde = dsde %>% inner_join( categoryCombos,  by = "dataSet")
    }


    # Data elements in data.totals
    de = data_totals %>% select( dataElement ) %>% distinct 
    
    # display with names
    datasetsWithDE = dsde %>%
        left_join( md$dataSets %>% select( id, name ), 
                   by = c("dataSet"="id")
                   ) %>%
        select( -dataSet ) %>%
        rename( dataSet = name ) %>% 
        left_join( md$dataElements %>% select( id, name ), 
                   by = c("dataElement"="id")
                   ) %>%
        select( -dataElement ) %>%
        rename( dataElement = name ) %>% 
        left_join( md$categoryCombos %>% select( id, name ), 
                   by = c("categoryCombo"="id")
                   ) %>%
        select( -categoryCombo ) %>%
        rename( categoryCombo = name ) 
        
        datatable( datasetsWithDE , rownames = FALSE,
                   options= list( pageLength = 15 ,
                                  scrollY = TRUE)
                   ) 

  
```


# Data Completeness {.tabset .tabset-fade}

Values shown are for the periods from `r min(periods.vector)` to `r max(periods.vector)`.


```{r download_dataset_submissions }
## DataElements : details 

  dataset.submission.file = paste0( origin.folder , 
                     dhis_instance ,  
                     "_dataset_submissions.rds" )

    if ( !file.exists( dataset.submission.file ) | params$create_new ){
            
        data_submissions = api_data( periods = periods.vector , 
                                levels = levels.vector , 
                                de.vars = de.include ,
                                file = dataset.submission.file ,
                                dsde = dsde ,
                                details = FALSE , 
                                submissions =  TRUE )
        
    } else {
        
        data_submissions = readRDS( dataset.submission.file ) 
        
    }         
          
    
   # Rename existing file
   if ( file.exists( dataset.submission.file ) & params$create_new ){
        
        file.rename( dataset.submission.file ,
                     paste( dataset.submission.file ,
                            format( Sys.time(), "%b%d%Y" )
                            )
                     )
    }
    
    # save new
    if ( !file.exists( dataset.submission.file) ) saveRDS( data_submissions , dataset.submission.file )

    # get date
    data_submissions_date = file.info( dataset.submission.file )$mtime

```


## Dataset 'Completeness' (form submission rate) 

- Dataset 'completeness', better described as form submission rate because it indicates the number of facilties that submitted a report, regardless of th completeness of the report.   

<!-- What would be really cool--to show number of orgunits available, assigned to dataset, and actually submitted data for each dataset/data element. -->

```{r dataset_completeness }
  
  d.ous = data_submissions %>% select( -level ) %>%
        separate( col = dataElement , 
                  into = c('dataSet', 'Category' ), 
                  sep = "\\.") %>%
        inner_join( md$dataSets %>% select( id, name ) , 
                    by = c( 'dataSet' = 'id') ) %>% 
        rename( dataSet = name , dataSet.id = dataSet) %>% 
        inner_join( ous %>% select( ous, parent, level, level.name , feature, id ), 
                    by = c( 'orgUnit' = 'id' ) 
                        ) 
    
                     
  s = d.ous  %>%
    # mutate( 
    #     ous = fct_reorder( ous, level )
    #     ) %>%
    group_by( period, level, level.name , dataSet , Category ) %>%
    summarise( report = n() )  %>% 
    left_join( count( ous, level ) , by = 'level' ) %>%
    mutate( completeness = report / n ) %>%
    ungroup()
  
  # convert month-Yr to date
  s$date = fast_strptime( as.character(  s$period ) , "%Y%m") %>% as.POSIXct()
  
```

This chart shows the percentage of active organisational units that were expected to report during each period.  Any value less than 100% indicates that some organisational units were not assigned the dataset report.  

```{r expected_reports}
  # summary( s$completeness )
  
    ggplot(s %>% filter( Category %in% "EXPECTED_REPORTS" ),  
           aes(x = date, y = completeness, 
                   group = level.name , color = level.name )) +
    geom_line() +
    facet_wrap( ~ dataSet, 
                labeller = label_wrap_gen( width = 25, multi_line = TRUE) ,
                ncol = 4
                ) +
    labs( title = 'Percent of OrgUnits Expected to Report', 
             subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance ,
          x = "Percent"
             ) +
    scale_y_continuous(labels = scales::percent)
  
```


This chart shows the perecentage of active organisational units that reported, and reported on time, during each period.  Completeness is shown by level, because a report was submitted at upper levels does not indicate the percentage of reports submitted by the lower levels organisation units. **Attention should be given to the lowest level, e.g. health facilities, where data is reported.** 

```{r actual_reports}
  # summary( s$completeness )
  
if ( s %>% filter( Category %in% "ACTUAL_REPORTS" ) %>% nrow > 0 ){
    
    ggplot( s %>% filter( Category %in% "ACTUAL_REPORTS" ),  
            aes(x = date, y = completeness,
                group = level.name , color = level.name )
            ) +
    geom_line() +
    facet_wrap( ~ dataSet, 
                labeller = label_wrap_gen( width = 25, multi_line = TRUE) ,
                ncol = 4
                ) +
        
    labs( title = 'Percentage of Expected Recports Submitted', 
             subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance
             ) +
        
    scale_y_continuous(labels = scales::percent)
    
} else {
    
    cat("No data available on submitted datasets.")
}
    
```

```{r actual_onTime_reports}
  # summary( s$completeness )
  
if ( s %>% filter( Category %in% "ACTUAL_REPORTS_ON_TIME" ) %>% nrow > 0 ){
    
    ggplot( s %>% filter( Category %in% "ACTUAL_REPORTS_ON_TIME" ),  
            aes(x = date, y = completeness,
                group = level.name , color = level.name )
            ) +
    geom_line() +
    facet_wrap( ~ dataSet, 
                labeller = label_wrap_gen( width = 25, multi_line = TRUE) ,
                ncol = 4
                ) +
        
    labs( title = 'Percentage of Expected Recports Submitted On-Time', 
             subtitle =  'denominator is current number of all org units' ,
             caption = params$dhis_instance
             ) +
        
    scale_y_continuous(labels = scales::percent)
    
} else {
    
    cat("No data available on submitted datasets.")
}
```

## Percent completeness by Data Element

- crude measure with denom = all orgunits

```{r Submission_de_details }

    s = data_totals %>% select( -level ) %>%
        left_join(  ous %>% select( id, level, level.name ) , 
                    by = c('orgUnit' = 'id') ) %>%
        count( dataElement , level, level.name , period ) %>% 
        rename( reported = n ) %>%
        left_join( count( ous, level ) , by = 'level' ) %>%
        rename( expected = n ) %>%
        mutate( 
            completeness = reported / expected 
            ) %>%
    
        # data element names 
        rename( id = dataElement ) %>%
        left_join( 
            md$dataElements %>% select( id, name ) , 
            by = c( 'id' ) 
            ) %>%
        rename( dataElement = name )

    # convert month-Yr to date
    s$date = fast_strptime( as.character(  s$period ) , "%Y%m") %>% as.POSIXct()
  
    # summary( s$completeness )
  

```

Subset to organizational unit levels with at least 20 expected reports

```{r de_completeness_charts}

# percent completeness 
    ggplot(s %>% filter(expected >=20 ),  aes(x = date, y = completeness, 
                   group = level.name , color = level.name )) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_wrap( ~ dataElement, 
                labeller = label_wrap_gen(width = 25, multi_line = TRUE) ,
                ncol = 4
                ) +
    labs( title = 'Percent completeness by level', 
             subtitle =  '' ,
             caption = params$origin_login_file
             ) +
    scale_y_continuous(labels = scales::percent)
    
    # ggplotly( g )
    
```

## Actual Number Reports by Data Element

```{r , out.height="150%"}
# Actual number
    ggplot(s %>% filter(expected >=20 ),  aes(x = date, y = reported, 
                   group = level.name , color = level.name )) +
    geom_line() +
    # scale_y_continuous(limits = c(0,NA)) +
    facet_wrap( ~ dataElement,
                labeller = label_wrap_gen(width = 25, multi_line = TRUE) ,
                ncol = 4
                ) +
    labs( title = 'Actual reports by level', 
             subtitle =  '' ,
             caption = params$origin_login_file
             ) +
    theme( strip.text = element_text( size = 6 ) )
```

## Reported dataElement by dataSet, level

Table of number of org units that provided data for each data element, stratified by dataset (row headings) and orgUnit level (column headings).  

```{r Submission_de_Totals }


 d = data_totals  %>% select( -level ) %>%
    
    # Remove any rows with all missing data
    filter( complete.cases(.) ) %>%
    
    # get ou level 
    left_join(
        select( ous , id, level ) , 
        by = c('orgUnit' = 'id')
    ) %>% 
    
    # join dataset to dataElement
    left_join( dsde, by = 'dataElement' ) %>%
    
    # Summarize by element and level--all dates
    group_by( dataSet, dataElement , level ) %>%
    summarise( n = n_distinct( orgUnit ) )   %>%
    ungroup %>%
     
    #dataset name
    rename( id = dataSet ) %>%
    left_join( md$dataSets %>% select( id, name ) ,  by = 'id'  ) %>%
    rename( dataSet = name ) %>%
    select( -id ) %>%
     
    # data element name
    rename( id  = dataElement ) %>%
    left_join( md$dataElements %>% select( id, name ) , by = 'id' ) %>%
    rename( dataElement = name ) %>%
    select( -id ) %>%
     
    spread( level, n ) 
 
 kable( d, 'html' ) %>% 
       kable_styling(bootstrap_options = c("striped", "hover") ) %>%
        column_spec(1, bold = T) 
```

- Summarise org units open each period

Limitation: Because only one openiningDate is recorded, if clinic was closed, then reoppened, it will be reported as if it was always open.  


<!-- NB:  Use API to save charts as favorites??? -->

<!-- Compare with indicators from other programs--tb, hiv, imm... -->

# Anomalies

This section will be to identify extreme values that are most likely data entry errors.  Some decisions will need to be made about whether to remove or replace those values for the rest of the anlyses. 

Detect outliers/anomalies:  
- WHO Outilier detection
- Anomallize

# Population and Attendance 
## Population

```{r population, eval=FALSE }


    data.populations.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_poulations.rds" )

    if ( file.exists( data.populations.file ) ){
        
          data_poulations = readRDS( data.populations.file ) 
          
# TODO: check for missing dates, then update 
          # - make fetch into a function usable for details, details, and datasets...
                                
          
    } else {
        
    # get selected rows from every spreadsheet tab
    de.include = map_df(  seq_along(sheets) , 
                         ~readxl::read_xlsx( de.review.xlsx ,  sheet = .x ) %>% 
        filter( !is.na(Include) ) %>% 
        distinct( dataElement.id, .keep_all = TRUE )
    )

    # if none selected, pick intersection of malaria and confirmed 
    if ( nrow( de.include) == 0 ){
        
        de.include = read_rds( paste0( origin.folder ,
                               dhis_instance, 
                               "_key_data_elements.rds" ) 
                            ) 
            
    }
            
        data_populations = api_data( periods = periods.vector , 
                                levels = levels.vector , 
                                de.vars = de.include ,
                                file = "" ,
                                details = TRUE , 
                                submissions =  FALSE )
        
        # save data
        write_rds( data_populations, data.populations.file )
 
    }

    # get date
    data_populations_date = file.info( data.populations.file )$mtime

```

## Attendance


```{r attendance , eval=FALSE }

    data.attendances.file = paste0( origin.folder , 
                     dhis_instance, 
                     "_attendances.rds" )

    if ( file.exists( data.attendances.file ) ){
        
          data_poulations = readRDS( data.attendances.file ) 
          
# TODO: check for missing dates, then update 
          # - make fetch into a function usable for details, details, and datasets...
                                
          
    } else {
        
        de.include =     
        
        data_attendances = api_data( periods = periods.vector , 
                                levels = levels.vector , 
                                de.vars = de.include ,
                                file = "" ,
                                details = TRUE , 
                                submissions =  FALSE )
        
        # save data
        write_rds( data_attendances, data.attendances.file )
 
    }

    # get date
    data_attendances_date = file.info( data.attendances.file )$mtime
```


# Field visits

- site selection options
